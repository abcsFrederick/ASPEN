{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Background \u00b6 The Assay for Transposase-Accessible Chromatin using sequencing (ATAC-seq) has revolutionized genomics by providing a rapid and sensitive method to assess chromatin accessibility across the genome. This technique offers profound insights into gene regulation, epigenetic modifications, and the dynamic landscape of the chromatin environment. To facilitate the comprehensive analysis of ATAC-seq data, the Center for Cancer Research (CCR) Collaborative Bioinformatics Resource (CCBR) has developed ASPEN ( A tac S eq P ip E li N e), an automated, robust, reproducible pipeline designed using the Snakemake pipelining framework to streamline the complexities inherent in ATAC-seq data processing.","title":"Background"},{"location":"#background","text":"The Assay for Transposase-Accessible Chromatin using sequencing (ATAC-seq) has revolutionized genomics by providing a rapid and sensitive method to assess chromatin accessibility across the genome. This technique offers profound insights into gene regulation, epigenetic modifications, and the dynamic landscape of the chromatin environment. To facilitate the comprehensive analysis of ATAC-seq data, the Center for Cancer Research (CCR) Collaborative Bioinformatics Resource (CCBR) has developed ASPEN ( A tac S eq P ip E li N e), an automated, robust, reproducible pipeline designed using the Snakemake pipelining framework to streamline the complexities inherent in ATAC-seq data processing.","title":"Background"},{"location":"changelog/","text":"ASPEN development version \u00b6 ASPEN 1.1.2 \u00b6 Fix broken data path for biowulf. (#104, @kelly-sovacool) Remove deprecated ccr partition. (#106, @kelly-sovacool) ASPEN 1.1.1 \u00b6 Fix Diffatac error (#101, @kopardev) Adds a defensive check to prevent invalid 'row.names' length error when up_roi or down_roi are empty (due to strict FC/FDR thresholds in DiffATAC) Minor refactoring to accommodate moving to ccbr_tools >= v0.4 (#101, @kopardev) ASPEN 1.1.0 \u00b6 This version features a major overhaul of the pipeline with changes in the following areas: Spike-in alignment (#94, @kopardev) \u00b6 Added support for spike-in alignment and scaling factor computation. (#94, @kopardev) This new feature is controlled by two new parameters in the config file: spikein and spikein_genome . (#69) Peak-calling (#94, @kopardev) \u00b6 Peak-called narrowPeak files are now q-value filtered by default, with a default q-value threshold of 0.1. Unfiltered files are still available for users who want to apply their own filters. (#90) Streamlined the output directory structure. Added the name of the peak-caller to ROI filenames (#86) Added missing annotations (#79) Differential accessibility (#94, @kopardev) \u00b6 Add new rules for scaling counts and annotating regions of interest. (#68) DiffATAC analysis is now run for both MACS2 and Genrich peak calls, with results stored in separate directories. DiffATAC analysis now includes spike-in scaling factors when spikein is TRUE . Removed redundant steps in the differential accessibility analysis to streamline the process. create Tn5-based and reads-based counts matrices (#67) create spike-in scaled counts matrices (#62) Quality control Updated FRiP calculation to use tagAlign.gz files instead of deduplicated BAM files. Removed unnecessary QC metrics and simplified the QC workflow. Updated TSS enrichment and fragment length distribution rules to align with the simplified pipeline structure. Output directory (#94, @kopardev) \u00b6 Consolidated peak calling outputs into a single directory for each peak caller. (#91) Simplified the output directory structure. (#92) Decreased output digital footprint by removing unwanted intermediate files, gzipping annotated files, etc. (#87) Improved slurm job logging with jobby (now depends on ccbr_tools v0.4). (#98, @kelly-sovacool) Documentation (#94, @kopardev) \u00b6 Simplified the documentation to focus on the core functionalities of the pipeline, as well as reflect all of the changes in this version. ASPEN 1.0.6 \u00b6 fix: dockername typo ( #57 , @kopardev) docs: update documentation, change theme ( #77 , #78 , @kopardev) ASPEN 1.0.5 \u00b6 fix: ucsc tool version changed requiring newer version of GLIBC ( #54 , @kopardev) using new masterdocker v11 ASPEN 1.0.4 \u00b6 fix: DiffATAC failure ( #46 , @kopardev) fix: last line of contrasts.tsv read in correctly; black lines ignored ( #48 , @kopardev) fix: ROI calculation from fixed-width consensus peaks no longer tried to fix the peak width again ( #50 , @kopardev) feature: create diffatac results from MACS2 peaks ( #51 , @kopardev) fix: BUYINPARTITIONS fixed in wrapper for BIOWULF-only ( #52 , @kopardev) ASPEN 1.0.3 \u00b6 fix: No module named 'numpy._core._multiarray_umath' error with unset PYTHONPATH ( #43 , @kopardev) fix: jobby command points to the correct location of snakemake.log file ASPEN is now archived on Zenodo, you can cite it with the DOI 10.5281/zenodo.13755867 . ( #42 , @kelly-sovacool) ASPEN 1.0.2 \u00b6 Set the singularity cache dir if --singcache is not provided. ( #37 , @kelly-sovacool) ASPEN now has a documentation website: https://ccbr.github.io/ASPEN ASPEN 1.0.1 \u00b6 differential ATAC updated documentation updated ASPEN 1.0.0 \u00b6 completely dockerized differential ATAC ASPEN 0.6.1 \u00b6 correction to fqscreen cattle path ASPEN 0.6 \u00b6 support for mmul10 (Macaca) and bosTau9 (cattle) genomes created resource files: indexes, promoter files, tss files etc. Added Macaca and Cattle to fastqscreen indexes support increased from 4 replicate to 6 replicates macs and genrich fixed width peaks generation rule added docker updated to v10 (genome support and tidyverse added) ASPEN 0.5.3 \u00b6 Includes reference files for mmul10 ASPEN 0.5.2 \u00b6 atac_assign_multimappers.py now getting query sorted input dryrun log saved in workdir local (workdir) scriptsdir used ASPEN 0.5.1 \u00b6 typo fix in main wrapper script ASPEN 0.5 \u00b6 fastqscreen added minor bug fixes ASPEN 0.4.1 \u00b6 Bug fixes minor updates ASPEN 0.4 \u00b6 Multiqc edits README updates ASPEN 0.3 \u00b6 FRiP calculations added ASPEN 0.2 \u00b6 Peak motif enrichment with homer/meme Peak replicate/sample/peakcaller PCA comparisons after bedtools jaccard pairwise calculations ASPEN 0.1 \u00b6 first working version calls peaks with macs2/genrich annotates peaks with chipseeker (human and mouse support)","title":"Change Log"},{"location":"changelog/#aspen-development-version","text":"","title":"ASPEN development version"},{"location":"changelog/#aspen-112","text":"Fix broken data path for biowulf. (#104, @kelly-sovacool) Remove deprecated ccr partition. (#106, @kelly-sovacool)","title":"ASPEN 1.1.2"},{"location":"changelog/#aspen-111","text":"Fix Diffatac error (#101, @kopardev) Adds a defensive check to prevent invalid 'row.names' length error when up_roi or down_roi are empty (due to strict FC/FDR thresholds in DiffATAC) Minor refactoring to accommodate moving to ccbr_tools >= v0.4 (#101, @kopardev)","title":"ASPEN 1.1.1"},{"location":"changelog/#aspen-110","text":"This version features a major overhaul of the pipeline with changes in the following areas:","title":"ASPEN 1.1.0"},{"location":"changelog/#spike-in-alignment-94-kopardev","text":"Added support for spike-in alignment and scaling factor computation. (#94, @kopardev) This new feature is controlled by two new parameters in the config file: spikein and spikein_genome . (#69)","title":"Spike-in alignment (#94, @kopardev)"},{"location":"changelog/#peak-calling-94-kopardev","text":"Peak-called narrowPeak files are now q-value filtered by default, with a default q-value threshold of 0.1. Unfiltered files are still available for users who want to apply their own filters. (#90) Streamlined the output directory structure. Added the name of the peak-caller to ROI filenames (#86) Added missing annotations (#79)","title":"Peak-calling (#94, @kopardev)"},{"location":"changelog/#differential-accessibility-94-kopardev","text":"Add new rules for scaling counts and annotating regions of interest. (#68) DiffATAC analysis is now run for both MACS2 and Genrich peak calls, with results stored in separate directories. DiffATAC analysis now includes spike-in scaling factors when spikein is TRUE . Removed redundant steps in the differential accessibility analysis to streamline the process. create Tn5-based and reads-based counts matrices (#67) create spike-in scaled counts matrices (#62) Quality control Updated FRiP calculation to use tagAlign.gz files instead of deduplicated BAM files. Removed unnecessary QC metrics and simplified the QC workflow. Updated TSS enrichment and fragment length distribution rules to align with the simplified pipeline structure.","title":"Differential accessibility (#94, @kopardev)"},{"location":"changelog/#output-directory-94-kopardev","text":"Consolidated peak calling outputs into a single directory for each peak caller. (#91) Simplified the output directory structure. (#92) Decreased output digital footprint by removing unwanted intermediate files, gzipping annotated files, etc. (#87) Improved slurm job logging with jobby (now depends on ccbr_tools v0.4). (#98, @kelly-sovacool)","title":"Output directory (#94, @kopardev)"},{"location":"changelog/#documentation-94-kopardev","text":"Simplified the documentation to focus on the core functionalities of the pipeline, as well as reflect all of the changes in this version.","title":"Documentation (#94, @kopardev)"},{"location":"changelog/#aspen-106","text":"fix: dockername typo ( #57 , @kopardev) docs: update documentation, change theme ( #77 , #78 , @kopardev)","title":"ASPEN 1.0.6"},{"location":"changelog/#aspen-105","text":"fix: ucsc tool version changed requiring newer version of GLIBC ( #54 , @kopardev) using new masterdocker v11","title":"ASPEN 1.0.5"},{"location":"changelog/#aspen-104","text":"fix: DiffATAC failure ( #46 , @kopardev) fix: last line of contrasts.tsv read in correctly; black lines ignored ( #48 , @kopardev) fix: ROI calculation from fixed-width consensus peaks no longer tried to fix the peak width again ( #50 , @kopardev) feature: create diffatac results from MACS2 peaks ( #51 , @kopardev) fix: BUYINPARTITIONS fixed in wrapper for BIOWULF-only ( #52 , @kopardev)","title":"ASPEN 1.0.4"},{"location":"changelog/#aspen-103","text":"fix: No module named 'numpy._core._multiarray_umath' error with unset PYTHONPATH ( #43 , @kopardev) fix: jobby command points to the correct location of snakemake.log file ASPEN is now archived on Zenodo, you can cite it with the DOI 10.5281/zenodo.13755867 . ( #42 , @kelly-sovacool)","title":"ASPEN 1.0.3"},{"location":"changelog/#aspen-102","text":"Set the singularity cache dir if --singcache is not provided. ( #37 , @kelly-sovacool) ASPEN now has a documentation website: https://ccbr.github.io/ASPEN","title":"ASPEN 1.0.2"},{"location":"changelog/#aspen-101","text":"differential ATAC updated documentation updated","title":"ASPEN 1.0.1"},{"location":"changelog/#aspen-100","text":"completely dockerized differential ATAC","title":"ASPEN 1.0.0"},{"location":"changelog/#aspen-061","text":"correction to fqscreen cattle path","title":"ASPEN 0.6.1"},{"location":"changelog/#aspen-06","text":"support for mmul10 (Macaca) and bosTau9 (cattle) genomes created resource files: indexes, promoter files, tss files etc. Added Macaca and Cattle to fastqscreen indexes support increased from 4 replicate to 6 replicates macs and genrich fixed width peaks generation rule added docker updated to v10 (genome support and tidyverse added)","title":"ASPEN 0.6"},{"location":"changelog/#aspen-053","text":"Includes reference files for mmul10","title":"ASPEN 0.5.3"},{"location":"changelog/#aspen-052","text":"atac_assign_multimappers.py now getting query sorted input dryrun log saved in workdir local (workdir) scriptsdir used","title":"ASPEN 0.5.2"},{"location":"changelog/#aspen-051","text":"typo fix in main wrapper script","title":"ASPEN 0.5.1"},{"location":"changelog/#aspen-05","text":"fastqscreen added minor bug fixes","title":"ASPEN 0.5"},{"location":"changelog/#aspen-041","text":"Bug fixes minor updates","title":"ASPEN 0.4.1"},{"location":"changelog/#aspen-04","text":"Multiqc edits README updates","title":"ASPEN 0.4"},{"location":"changelog/#aspen-03","text":"FRiP calculations added","title":"ASPEN 0.3"},{"location":"changelog/#aspen-02","text":"Peak motif enrichment with homer/meme Peak replicate/sample/peakcaller PCA comparisons after bedtools jaccard pairwise calculations","title":"ASPEN 0.2"},{"location":"changelog/#aspen-01","text":"first working version calls peaks with macs2/genrich annotates peaks with chipseeker (human and mouse support)","title":"ASPEN 0.1"},{"location":"communications/","text":"\ud83d\udce2 Communications About ASPEN: \u00b6 To facilitate effective interaction and support for ASPEN (ATAC-Seq PipEliNe) users, we have established the following communication channels: Feature Requests: If you have suggestions for new features or enhancements, please submit them by opening a new issue on our GitHub repository. Before doing so, we recommend reviewing the existing issues to ensure your suggestion hasn't already been addressed. Bug Reports: To report any bugs or issues encountered while using ASPEN, kindly open a new issue on our GitHub repository. Provide a detailed description of the problem, including steps to reproduce it, and attach relevant screenshots or logs to assist in diagnosing the issue. General Inquiries and Collaboration: For general questions, assistance with getting started, interpretation of results, or discussions about potential collaborations, please contact the CCBR Pipeliner team at CCBR_Pipeliner@nih.gov or reach out directly to Dr. Vishal Koparde at vishal.koparde@nih.gov . By utilizing these channels, we aim to provide prompt and effective support, fostering a collaborative environment for all ASPEN users.","title":"Communications"},{"location":"communications/#communications-about-aspen","text":"To facilitate effective interaction and support for ASPEN (ATAC-Seq PipEliNe) users, we have established the following communication channels: Feature Requests: If you have suggestions for new features or enhancements, please submit them by opening a new issue on our GitHub repository. Before doing so, we recommend reviewing the existing issues to ensure your suggestion hasn't already been addressed. Bug Reports: To report any bugs or issues encountered while using ASPEN, kindly open a new issue on our GitHub repository. Provide a detailed description of the problem, including steps to reproduce it, and attach relevant screenshots or logs to assist in diagnosing the issue. General Inquiries and Collaboration: For general questions, assistance with getting started, interpretation of results, or discussions about potential collaborations, please contact the CCBR Pipeliner team at CCBR_Pipeliner@nih.gov or reach out directly to Dr. Vishal Koparde at vishal.koparde@nih.gov . By utilizing these channels, we aim to provide prompt and effective support, fostering a collaborative environment for all ASPEN users.","title":"\ud83d\udce2 Communications About ASPEN:"},{"location":"contributing/","text":"Contributing to ASPEN \u00b6 Proposing changes with issues \u00b6 If you want to make a change, it's a good idea to first open an issue and make sure someone from the team agrees that it\u2019s needed. If you've decided to work on an issue, assign yourself to the issue so others will know you're working on it. Pull request process \u00b6 We use GitHub Flow as our collaboration process. Follow the steps below for detailed instructions on contributing changes to ASPEN. Clone the repo \u00b6 If you are a member of CCBR , you can clone this repository to your computer or development environment. Otherwise, you will first need to fork the repo and clone your fork. You only need to do this step once. git clone https://github.com/CCBR/ASPEN Cloning into 'ASPEN'... remote: Enumerating objects: 1136, done. remote: Counting objects: 100% (463/463), done. remote: Compressing objects: 100% (357/357), done. remote: Total 1136 (delta 149), reused 332 (delta 103), pack-reused 673 Receiving objects: 100% (1136/1136), 11.01 MiB | 9.76 MiB/s, done. Resolving deltas: 100% (530/530), done. cd ASPEN If this is your first time cloning the repo, you may need to install dependencies \u00b6 Install snakemake and singularity or docker if needed (biowulf already has these available as modules). Install the python dependencies with pip pip install . If you're developing on biowulf, you can use our shared conda environment which already has these dependencies installed . \"/data/CCBR_Pipeliner/db/PipeDB/Conda/etc/profile.d/conda.sh\" conda activate py311 Install pre-commit if you don't already have it. Then from the repo's root directory, run pre-commit install This will install the repo's pre-commit hooks. You'll only need to do this step the first time you clone the repo. Create a branch \u00b6 Create a Git branch for your pull request (PR). Give the branch a descriptive name for the changes you will make, such as iss-10 if it is for a specific issue. # create a new branch and switch to it git branch iss-10 git switch iss-10 Switched to a new branch 'iss-10' Make your changes \u00b6 Edit the code, write and run tests, and update the documentation as needed. test \u00b6 Changes to the python package code will also need unit tests to demonstrate that the changes work as intended. We write unit tests with pytest and store them in the tests/ subdirectory. Run the tests with python -m pytest . If you change the workflow , please run the workflow with the test profile and make sure your new feature or bug fix works as intended. document \u00b6 If you have added a new feature or changed the API of an existing feature, you will likely need to update the documentation in docs/ . Commit and push your changes \u00b6 If you're not sure how often you should commit or what your commits should consist of, we recommend following the \"atomic commits\" principle where each commit contains one new feature, fix, or task. Learn more about atomic commits here: https://www.freshconsulting.com/insights/blog/atomic-commits/ First, add the files that you changed to the staging area: git add path/to/changed/files/ Then make the commit. Your commit message should follow the Conventional Commits specification. Briefly, each commit should start with one of the approved types such as feat , fix , docs , etc. followed by a description of the commit. Take a look at the Conventional Commits specification for more detailed information about how to write commit messages. git commit -m 'feat: create function for awesome feature' pre-commit will enforce that your commit message and the code changes are styled correctly and will attempt to make corrections if needed. Check for added large files..............................................Passed Fix End of Files.........................................................Passed Trim Trailing Whitespace.................................................Failed hook id: trailing-whitespace exit code: 1 files were modified by this hook > Fixing path/to/changed/files/file.txt > codespell................................................................Passed style-files..........................................(no files to check)Skipped readme-rmd-rendered..................................(no files to check)Skipped use-tidy-description.................................(no files to check)Skipped In the example above, one of the hooks modified a file in the proposed commit, so the pre-commit check failed. You can run git diff to see the changes that pre-commit made and git status to see which files were modified. To proceed with the commit, re-add the modified file(s) and re-run the commit command: git add path/to/changed/files/file.txt git commit -m 'feat: create function for awesome feature' This time, all the hooks either passed or were skipped (e.g. hooks that only run on R code will not run if no R files were committed). When the pre-commit check is successful, the usual commit success message will appear after the pre-commit messages showing that the commit was created. Check for added large files..............................................Passed Fix End of Files.........................................................Passed Trim Trailing Whitespace.................................................Passed codespell................................................................Passed style-files..........................................(no files to check)Skipped readme-rmd-rendered..................................(no files to check)Skipped use-tidy-description.................................(no files to check)Skipped Conventional Commit......................................................Passed > [iss-10 9ff256e] feat: create function for awesome feature 1 file changed, 22 insertions(+), 3 deletions(-) Finally, push your changes to GitHub: git push If this is the first time you are pushing this branch, you may have to explicitly set the upstream branch: git push --set-upstream origin iss-10 Enumerating objects: 7, done. Counting objects: 100% (7/7), done. Delta compression using up to 10 threads Compressing objects: 100% (4/4), done. Writing objects: 100% (4/4), 648 bytes | 648.00 KiB/s, done. Total 4 (delta 3), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (3/3), completed with 3 local objects. remote: remote: Create a pull request for 'iss-10' on GitHub by visiting: remote: https://github.com/CCBR/ASPEN/pull/new/iss-10 remote: To https://github.com/CCBR/ASPEN > > [new branch] iss-10 -> iss-10 branch 'iss-10' set up to track 'origin/iss-10'. We recommend pushing your commits often so they will be backed up on GitHub. You can view the files in your branch on GitHub at https://github.com/CCBR/ASPEN/tree/<your-branch-name> (replace <your-branch-name> with the actual name of your branch). Create the PR \u00b6 Once your branch is ready, create a PR on GitHub: https://github.com/CCBR/ASPEN/pull/new/ Select the branch you just pushed: Edit the PR title and description. The title should briefly describe the change. Follow the comments in the template to fill out the body of the PR, and you can delete the comments (everything between <!-- and --> ) as you go. Be sure to fill out the checklist, checking off items as you complete them or striking through any irrelevant items. When you're ready, click 'Create pull request' to open it. Optionally, you can mark the PR as a draft if you're not yet ready for it to be reviewed, then change it later when you're ready. Wait for a maintainer to review your PR \u00b6 We will do our best to follow the tidyverse code review principles: https://code-review.tidyverse.org/ . The reviewer may suggest that you make changes before accepting your PR in order to improve the code quality or style. If that's the case, continue to make changes in your branch and push them to GitHub, and they will appear in the PR. Once the PR is approved, the maintainer will merge it and the issue(s) the PR links will close automatically. Congratulations and thank you for your contribution! After your PR has been merged \u00b6 After your PR has been merged, update your local clone of the repo by switching to the main branch and pulling the latest changes: git checkout main git pull It's a good idea to run git pull before creating a new branch so it will start from the most recent commits in main. Helpful links for more information \u00b6 GitHub Flow semantic versioning guidelines changelog guidelines tidyverse code review principles reproducible examples nf-core extensions for VS Code","title":"Contributing to ASPEN"},{"location":"contributing/#contributing-to-aspen","text":"","title":"Contributing to ASPEN"},{"location":"contributing/#proposing-changes-with-issues","text":"If you want to make a change, it's a good idea to first open an issue and make sure someone from the team agrees that it\u2019s needed. If you've decided to work on an issue, assign yourself to the issue so others will know you're working on it.","title":"Proposing changes with issues"},{"location":"contributing/#pull-request-process","text":"We use GitHub Flow as our collaboration process. Follow the steps below for detailed instructions on contributing changes to ASPEN.","title":"Pull request process"},{"location":"contributing/#clone-the-repo","text":"If you are a member of CCBR , you can clone this repository to your computer or development environment. Otherwise, you will first need to fork the repo and clone your fork. You only need to do this step once. git clone https://github.com/CCBR/ASPEN Cloning into 'ASPEN'... remote: Enumerating objects: 1136, done. remote: Counting objects: 100% (463/463), done. remote: Compressing objects: 100% (357/357), done. remote: Total 1136 (delta 149), reused 332 (delta 103), pack-reused 673 Receiving objects: 100% (1136/1136), 11.01 MiB | 9.76 MiB/s, done. Resolving deltas: 100% (530/530), done. cd ASPEN","title":"Clone the repo"},{"location":"contributing/#if-this-is-your-first-time-cloning-the-repo-you-may-need-to-install-dependencies","text":"Install snakemake and singularity or docker if needed (biowulf already has these available as modules). Install the python dependencies with pip pip install . If you're developing on biowulf, you can use our shared conda environment which already has these dependencies installed . \"/data/CCBR_Pipeliner/db/PipeDB/Conda/etc/profile.d/conda.sh\" conda activate py311 Install pre-commit if you don't already have it. Then from the repo's root directory, run pre-commit install This will install the repo's pre-commit hooks. You'll only need to do this step the first time you clone the repo.","title":"If this is your first time cloning the repo, you may need to install dependencies"},{"location":"contributing/#create-a-branch","text":"Create a Git branch for your pull request (PR). Give the branch a descriptive name for the changes you will make, such as iss-10 if it is for a specific issue. # create a new branch and switch to it git branch iss-10 git switch iss-10 Switched to a new branch 'iss-10'","title":"Create a branch"},{"location":"contributing/#make-your-changes","text":"Edit the code, write and run tests, and update the documentation as needed.","title":"Make your changes"},{"location":"contributing/#test","text":"Changes to the python package code will also need unit tests to demonstrate that the changes work as intended. We write unit tests with pytest and store them in the tests/ subdirectory. Run the tests with python -m pytest . If you change the workflow , please run the workflow with the test profile and make sure your new feature or bug fix works as intended.","title":"test"},{"location":"contributing/#document","text":"If you have added a new feature or changed the API of an existing feature, you will likely need to update the documentation in docs/ .","title":"document"},{"location":"contributing/#commit-and-push-your-changes","text":"If you're not sure how often you should commit or what your commits should consist of, we recommend following the \"atomic commits\" principle where each commit contains one new feature, fix, or task. Learn more about atomic commits here: https://www.freshconsulting.com/insights/blog/atomic-commits/ First, add the files that you changed to the staging area: git add path/to/changed/files/ Then make the commit. Your commit message should follow the Conventional Commits specification. Briefly, each commit should start with one of the approved types such as feat , fix , docs , etc. followed by a description of the commit. Take a look at the Conventional Commits specification for more detailed information about how to write commit messages. git commit -m 'feat: create function for awesome feature' pre-commit will enforce that your commit message and the code changes are styled correctly and will attempt to make corrections if needed. Check for added large files..............................................Passed Fix End of Files.........................................................Passed Trim Trailing Whitespace.................................................Failed hook id: trailing-whitespace exit code: 1 files were modified by this hook > Fixing path/to/changed/files/file.txt > codespell................................................................Passed style-files..........................................(no files to check)Skipped readme-rmd-rendered..................................(no files to check)Skipped use-tidy-description.................................(no files to check)Skipped In the example above, one of the hooks modified a file in the proposed commit, so the pre-commit check failed. You can run git diff to see the changes that pre-commit made and git status to see which files were modified. To proceed with the commit, re-add the modified file(s) and re-run the commit command: git add path/to/changed/files/file.txt git commit -m 'feat: create function for awesome feature' This time, all the hooks either passed or were skipped (e.g. hooks that only run on R code will not run if no R files were committed). When the pre-commit check is successful, the usual commit success message will appear after the pre-commit messages showing that the commit was created. Check for added large files..............................................Passed Fix End of Files.........................................................Passed Trim Trailing Whitespace.................................................Passed codespell................................................................Passed style-files..........................................(no files to check)Skipped readme-rmd-rendered..................................(no files to check)Skipped use-tidy-description.................................(no files to check)Skipped Conventional Commit......................................................Passed > [iss-10 9ff256e] feat: create function for awesome feature 1 file changed, 22 insertions(+), 3 deletions(-) Finally, push your changes to GitHub: git push If this is the first time you are pushing this branch, you may have to explicitly set the upstream branch: git push --set-upstream origin iss-10 Enumerating objects: 7, done. Counting objects: 100% (7/7), done. Delta compression using up to 10 threads Compressing objects: 100% (4/4), done. Writing objects: 100% (4/4), 648 bytes | 648.00 KiB/s, done. Total 4 (delta 3), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (3/3), completed with 3 local objects. remote: remote: Create a pull request for 'iss-10' on GitHub by visiting: remote: https://github.com/CCBR/ASPEN/pull/new/iss-10 remote: To https://github.com/CCBR/ASPEN > > [new branch] iss-10 -> iss-10 branch 'iss-10' set up to track 'origin/iss-10'. We recommend pushing your commits often so they will be backed up on GitHub. You can view the files in your branch on GitHub at https://github.com/CCBR/ASPEN/tree/<your-branch-name> (replace <your-branch-name> with the actual name of your branch).","title":"Commit and push your changes"},{"location":"contributing/#create-the-pr","text":"Once your branch is ready, create a PR on GitHub: https://github.com/CCBR/ASPEN/pull/new/ Select the branch you just pushed: Edit the PR title and description. The title should briefly describe the change. Follow the comments in the template to fill out the body of the PR, and you can delete the comments (everything between <!-- and --> ) as you go. Be sure to fill out the checklist, checking off items as you complete them or striking through any irrelevant items. When you're ready, click 'Create pull request' to open it. Optionally, you can mark the PR as a draft if you're not yet ready for it to be reviewed, then change it later when you're ready.","title":"Create the PR"},{"location":"contributing/#wait-for-a-maintainer-to-review-your-pr","text":"We will do our best to follow the tidyverse code review principles: https://code-review.tidyverse.org/ . The reviewer may suggest that you make changes before accepting your PR in order to improve the code quality or style. If that's the case, continue to make changes in your branch and push them to GitHub, and they will appear in the PR. Once the PR is approved, the maintainer will merge it and the issue(s) the PR links will close automatically. Congratulations and thank you for your contribution!","title":"Wait for a maintainer to review your PR"},{"location":"contributing/#after-your-pr-has-been-merged","text":"After your PR has been merged, update your local clone of the repo by switching to the main branch and pulling the latest changes: git checkout main git pull It's a good idea to run git pull before creating a new branch so it will start from the most recent commits in main.","title":"After your PR has been merged"},{"location":"contributing/#helpful-links-for-more-information","text":"GitHub Flow semantic versioning guidelines changelog guidelines tidyverse code review principles reproducible examples nf-core extensions for VS Code","title":"Helpful links for more information"},{"location":"deployment/","text":"Running ASPEN \u00b6 To effectively run the ASPEN (ATAC-Seq PipEliNe) on the Biowulf High-Performance Computing (HPC) system, please follow the detailed user guide below: \ud83d\udee0\ufe0f Prerequisites \u00b6 Biowulf Account: Ensure you have an active Biowulf account. Data Preparation: Store your raw ATAC-Seq paired-end FASTQ files in a directory accessible from Biowulf. \ud83c\udf10 Setting Up the Environment \u00b6 \ud83d\ude80 Load the ASPEN Module on Biowulf \u00b6 To access ASPEN, load the ccbrpipeliner module: module load ccbrpipeliner/8 This command adds aspen to your system's PATH, allowing you to execute pipeline commands directly. Note : If you're operating outside of Biowulf, ensure that dependencies such as snakemake, python, and singularity are installed and accessible in your system's PATH. \ud83d\udcdd Create a Sample Manifest \u00b6 ASPEN requires a sample manifest file ( samples.tsv ) to identify and organize your input data. This tab-separated file should include the following columns: replicateName : Unique identifier for each replicate. sampleName : Identifier for the sample; multiple replicates can share the same sample name. path_to_R1_fastq : Absolute path to the Read 1 FASTQ file. path_to_R2_fastq : Absolute path to the Read 2 FASTQ file (required for paired-end data). Note Symlinks for R1 and R2 files will be created in the results directory, named as .R1.fastq.gz and .R2.fastq.gz, respectively. Therefore, original filenames do not need to be altered. Note The replicateName is used as a prefix for individual peak calls, while the sampleName serves as a prefix for consensus peak calls. Note For differential ATAC analysis, create a contrasts.tsv file with two columns (Group1 and Group2 ... aka Sample1 and Sample2, without headers) and place it in the output directory after initialization. Ensure each group/sample in the contrast has at least two replicates, as DESeq2 requires this for accurate contrast calculations. \ud83c\udfc3 Running the ASPEN Pipeline \u00b6 ASPEN operates through a series of modes to facilitate various stages of the analysis. \ud83d\uddc2\ufe0f Initialize the Working Directory \u00b6 Begin by initializing your working directory, which will house configuration files and results. Replace with your desired output directory path: aspen -m = init -w = <path_to_output_folder> This command generates a config.yaml and a placeholder samples.tsv in the specified directory. Edit these files to reflect your experimental setup, replacing the placeholder samples.tsv with your prepared manifest. If performing differential analysis, include the contrasts.tsv file at this stage. Note To explore all possible options of the aspen command you can either run it without any arguments or run aspen --help Here is what help looks like: ########################################################################################## Welcome to ____ ____ ___ ____ _ _ | __ | [ __ | __ ] | ___ | \\ | | | ___ ] | | ___ | \\| A_TAC_S_eq A_nalysis P_ip_E_li_N_e ########################################################################################## This pipeline was built by CCBR ( https://bioinformatics.ccr.cancer.gov/ccbr ) Please contact Vishal Koparde for comments/questions ( vishal.koparde@nih.gov ) ########################################################################################## Here is a list of genome supported by aspen: * hg19 [ Human ] * hg38 [ Human ] * mm10 [ Mouse ] * mmul10 [ Macaca mulatta ( Rhesus monkey ) or rheMac10 ] * bosTau9 [ Bos taurus ( cattle )] aspen calls peaks using the following tools: * MACS2 * Genrich [ RECOMMENDED FOR USE ] USAGE: bash ./aspen -w/--workdir = <WORKDIR> -m/--runmode = <RUNMODE> Required Arguments: 1 . WORKDIR : [ Type: String ] : Absolute or relative path to the output folder with write permissions. 2 . RUNMODE : [ Type: String ] Valid options: * init : initialize workdir * dryrun : dry run snakemake to generate DAG * run : run with slurm * runlocal : run without submitting to sbatch ADVANCED RUNMODES ( use with caution!! ) * unlock : unlock WORKDIR if locked by snakemake NEVER UNLOCK WORKDIR WHERE PIPELINE IS CURRENTLY RUNNING! * reconfig : recreate config file in WORKDIR ( debugging option ) EDITS TO config.yaml WILL BE LOST! * reset : DELETE workdir dir and re-init it ( debugging option ) EDITS TO ALL FILES IN WORKDIR WILL BE LOST! * printbinds: print singularity binds ( paths ) * local : same as runlocal Optional Arguments: --genome | -g : genome eg. hg38 --manifest | -s : absolute path to samples.tsv. This will be copied to output folder ( --runmode = init only ) --help | -h : print this help Example commands: bash ./aspen -w = /my/output/folder -m = init bash ./aspen -w = /my/output/folder -m = dryrun bash ./aspen -w = /my/output/folder -m = run ########################################################################################## VersionInfo: python : python/3.10 snakemake : snakemake pipeline_home : /data/CCBR_Pipeliner/Pipelines/ASPEN/feature_spikeins git commit/tag : fc0699d6a7f9766963c8e7020c01214966616fab v1.0.6-29-gfc0699d aspen_version : v1.0.6-dev-spikeins ########################################################################################## \u2699\ufe0f Configurational Changes \u00b6 MACS2 \u00b6 MACS2 parameters can be changed by editing this block in the config.yaml : macs2 : extsize : 200 shiftsize : 100 p : 0.01 qfilter : 0.05 annotatePeaks : True Genrich \u00b6 Genrich paramaters can be changed by editing this block in the config.yaml : genrich : s : 5 m : 6 q : 1 l : 100 g : 100 d : 100 qfilter : 0.05 annotatePeaks : True Contrasts \u00b6 If contrasts are to be calculated then fixed-width peaks are used with the following changable options: # peak fixed width fixed_width : 500 # contrasts info contrasts : \"WORKDIR/contrasts.tsv\" contrasts_fc_cutoff : 2 contrasts_fdr_cutoff : 0.05 \ud83e\uddec Enabling Spike-In Normalization (Optional) \u00b6 ASPEN supports spike-in normalization, which is useful for controlling technical variability or comparing global shifts in chromatin accessibility across samples. Spike-in reads (e.g., from Drosophila melanogaster or E. coli ) are aligned separately and used to compute normalization factors that are applied to host genome accessibility counts. To enable spike-in normalization, edit the config.yaml file that was generated during init . You can find it in your output directory ( <path_to_output_folder>/config.yaml ). Open the file and locate the following lines: spikein: False # spikein: True spikein_genome: \"dmelr6.32\" # Drosophila mel. # spikein_genome: \"ecoli_k12\" # E. coli To activate spike-in normalization: Set spikein to True Uncomment or change the spikein_genome to match your experiment \ud83d\udcdd Example Configuration \u00b6 For Drosophila spike-in: spikein: True spikein_genome: \"dmelr6.32\" For E. coli spike-in: spikein: True spikein_genome: \"ecoli_k12\" Note : The spike-in genome must be pre-indexed and available in the reference directory used by ASPEN. Please contact the pipeline maintainers if you need to add a new spike-in genome. Once enabled, ASPEN will: Align reads to both the host and spike-in genomes. Quantify spike-in counts per sample. Normalize accessibility counts using spike-in-derived scaling factors. Report both normalized and raw counts in the output tables and reports. This step is optional but highly recommended when you expect global changes in chromatin accessibility due to treatments or perturbations. \ud83d\udee0\ufe0f Dry Run the Pipeline \u00b6 Before executing the full analysis and after editing the config.yaml as needed, perform a dry run to visualize the workflow and identify potential issues: aspen -m = dryrun -w = <path_to_output_folder> This step outlines the sequence of tasks (Directed Acyclic Graph - DAG) without actual execution, allowing you to verify the planned operations. \ud83d\ude80 Execute the Pipeline \u00b6 If the dry run output is satisfactory, proceed to execute the pipeline: aspen -m = run -w = <path_to_output_folder> This command submits a master job to the Slurm workload manager, which orchestrates the entire analysis workflow, managing job submissions and monitoring progress. \ud83d\udee0\ufe0f Optional Argument : --singcache or -c : Specify a Singularity cache directory. The default is /data/${USER}/.singularity if available; otherwise, it defaults to ${WORKDIR}/snakemake/.singularity . \ud83d\udca1 Example Command : aspen -m = run -w = <path_to_output_folder> -c /data/ ${ USER } /.singularity This command runs the pipeline with the specified working directory and Singularity cache directory. Note : If deploying on Biowulf, try setting the --singcache to /data/CCBR_Pipeliner/SIFS to reuse the pre-pulled containers and save time. \ud83d\udcca Monitor ASPEN Runs \u00b6 To monitor the status of your ASPEN pipeline and its associated jobs on a Slurm-managed system, you can utilize the squeue and scontrol commands. The squeue command provides information about jobs in the scheduling queue, while scontrol offers detailed insights into specific jobs. To view all your active and pending jobs, execute: squeue -u $USER --format = \"%.18i %.30j %.11P %.15T %.10r %.10M %.10l %.5D %.5C %.10m %.25b %.8N\" --sort = -S This command lists all jobs submitted by your user account, displaying details such as job IDs, partitions, job names, user names, job states, and the nodes allocated. For more granular information about a specific job, including its child jobs spawned by ASPEN, use the scontrol command: scontrol show job <jobid> Replace with the specific Job ID of interest. This will provide comprehensive details about the job's configuration and status, aiding in effective monitoring and management of your ASPEN pipeline processes. To quickly guage the process of the entire pipeline run: grep \"done $ \" <path_to_output_folder>/snakemake.log","title":"Running ASPEN"},{"location":"deployment/#running-aspen","text":"To effectively run the ASPEN (ATAC-Seq PipEliNe) on the Biowulf High-Performance Computing (HPC) system, please follow the detailed user guide below:","title":"Running ASPEN"},{"location":"deployment/#prerequisites","text":"Biowulf Account: Ensure you have an active Biowulf account. Data Preparation: Store your raw ATAC-Seq paired-end FASTQ files in a directory accessible from Biowulf.","title":"\ud83d\udee0\ufe0f Prerequisites"},{"location":"deployment/#setting-up-the-environment","text":"","title":"\ud83c\udf10 Setting Up the Environment"},{"location":"deployment/#load-the-aspen-module-on-biowulf","text":"To access ASPEN, load the ccbrpipeliner module: module load ccbrpipeliner/8 This command adds aspen to your system's PATH, allowing you to execute pipeline commands directly. Note : If you're operating outside of Biowulf, ensure that dependencies such as snakemake, python, and singularity are installed and accessible in your system's PATH.","title":"\ud83d\ude80 Load the ASPEN Module on Biowulf"},{"location":"deployment/#create-a-sample-manifest","text":"ASPEN requires a sample manifest file ( samples.tsv ) to identify and organize your input data. This tab-separated file should include the following columns: replicateName : Unique identifier for each replicate. sampleName : Identifier for the sample; multiple replicates can share the same sample name. path_to_R1_fastq : Absolute path to the Read 1 FASTQ file. path_to_R2_fastq : Absolute path to the Read 2 FASTQ file (required for paired-end data). Note Symlinks for R1 and R2 files will be created in the results directory, named as .R1.fastq.gz and .R2.fastq.gz, respectively. Therefore, original filenames do not need to be altered. Note The replicateName is used as a prefix for individual peak calls, while the sampleName serves as a prefix for consensus peak calls. Note For differential ATAC analysis, create a contrasts.tsv file with two columns (Group1 and Group2 ... aka Sample1 and Sample2, without headers) and place it in the output directory after initialization. Ensure each group/sample in the contrast has at least two replicates, as DESeq2 requires this for accurate contrast calculations.","title":"\ud83d\udcdd Create a Sample Manifest"},{"location":"deployment/#running-the-aspen-pipeline","text":"ASPEN operates through a series of modes to facilitate various stages of the analysis.","title":"\ud83c\udfc3 Running the ASPEN Pipeline"},{"location":"deployment/#initialize-the-working-directory","text":"Begin by initializing your working directory, which will house configuration files and results. Replace with your desired output directory path: aspen -m = init -w = <path_to_output_folder> This command generates a config.yaml and a placeholder samples.tsv in the specified directory. Edit these files to reflect your experimental setup, replacing the placeholder samples.tsv with your prepared manifest. If performing differential analysis, include the contrasts.tsv file at this stage. Note To explore all possible options of the aspen command you can either run it without any arguments or run aspen --help Here is what help looks like: ########################################################################################## Welcome to ____ ____ ___ ____ _ _ | __ | [ __ | __ ] | ___ | \\ | | | ___ ] | | ___ | \\| A_TAC_S_eq A_nalysis P_ip_E_li_N_e ########################################################################################## This pipeline was built by CCBR ( https://bioinformatics.ccr.cancer.gov/ccbr ) Please contact Vishal Koparde for comments/questions ( vishal.koparde@nih.gov ) ########################################################################################## Here is a list of genome supported by aspen: * hg19 [ Human ] * hg38 [ Human ] * mm10 [ Mouse ] * mmul10 [ Macaca mulatta ( Rhesus monkey ) or rheMac10 ] * bosTau9 [ Bos taurus ( cattle )] aspen calls peaks using the following tools: * MACS2 * Genrich [ RECOMMENDED FOR USE ] USAGE: bash ./aspen -w/--workdir = <WORKDIR> -m/--runmode = <RUNMODE> Required Arguments: 1 . WORKDIR : [ Type: String ] : Absolute or relative path to the output folder with write permissions. 2 . RUNMODE : [ Type: String ] Valid options: * init : initialize workdir * dryrun : dry run snakemake to generate DAG * run : run with slurm * runlocal : run without submitting to sbatch ADVANCED RUNMODES ( use with caution!! ) * unlock : unlock WORKDIR if locked by snakemake NEVER UNLOCK WORKDIR WHERE PIPELINE IS CURRENTLY RUNNING! * reconfig : recreate config file in WORKDIR ( debugging option ) EDITS TO config.yaml WILL BE LOST! * reset : DELETE workdir dir and re-init it ( debugging option ) EDITS TO ALL FILES IN WORKDIR WILL BE LOST! * printbinds: print singularity binds ( paths ) * local : same as runlocal Optional Arguments: --genome | -g : genome eg. hg38 --manifest | -s : absolute path to samples.tsv. This will be copied to output folder ( --runmode = init only ) --help | -h : print this help Example commands: bash ./aspen -w = /my/output/folder -m = init bash ./aspen -w = /my/output/folder -m = dryrun bash ./aspen -w = /my/output/folder -m = run ########################################################################################## VersionInfo: python : python/3.10 snakemake : snakemake pipeline_home : /data/CCBR_Pipeliner/Pipelines/ASPEN/feature_spikeins git commit/tag : fc0699d6a7f9766963c8e7020c01214966616fab v1.0.6-29-gfc0699d aspen_version : v1.0.6-dev-spikeins ##########################################################################################","title":"\ud83d\uddc2\ufe0f Initialize the Working Directory"},{"location":"deployment/#configurational-changes","text":"","title":"\u2699\ufe0f Configurational Changes"},{"location":"deployment/#macs2","text":"MACS2 parameters can be changed by editing this block in the config.yaml : macs2 : extsize : 200 shiftsize : 100 p : 0.01 qfilter : 0.05 annotatePeaks : True","title":"MACS2"},{"location":"deployment/#genrich","text":"Genrich paramaters can be changed by editing this block in the config.yaml : genrich : s : 5 m : 6 q : 1 l : 100 g : 100 d : 100 qfilter : 0.05 annotatePeaks : True","title":"Genrich"},{"location":"deployment/#contrasts","text":"If contrasts are to be calculated then fixed-width peaks are used with the following changable options: # peak fixed width fixed_width : 500 # contrasts info contrasts : \"WORKDIR/contrasts.tsv\" contrasts_fc_cutoff : 2 contrasts_fdr_cutoff : 0.05","title":"Contrasts"},{"location":"deployment/#enabling-spike-in-normalization-optional","text":"ASPEN supports spike-in normalization, which is useful for controlling technical variability or comparing global shifts in chromatin accessibility across samples. Spike-in reads (e.g., from Drosophila melanogaster or E. coli ) are aligned separately and used to compute normalization factors that are applied to host genome accessibility counts. To enable spike-in normalization, edit the config.yaml file that was generated during init . You can find it in your output directory ( <path_to_output_folder>/config.yaml ). Open the file and locate the following lines: spikein: False # spikein: True spikein_genome: \"dmelr6.32\" # Drosophila mel. # spikein_genome: \"ecoli_k12\" # E. coli To activate spike-in normalization: Set spikein to True Uncomment or change the spikein_genome to match your experiment","title":"\ud83e\uddec Enabling Spike-In Normalization (Optional)"},{"location":"deployment/#example-configuration","text":"For Drosophila spike-in: spikein: True spikein_genome: \"dmelr6.32\" For E. coli spike-in: spikein: True spikein_genome: \"ecoli_k12\" Note : The spike-in genome must be pre-indexed and available in the reference directory used by ASPEN. Please contact the pipeline maintainers if you need to add a new spike-in genome. Once enabled, ASPEN will: Align reads to both the host and spike-in genomes. Quantify spike-in counts per sample. Normalize accessibility counts using spike-in-derived scaling factors. Report both normalized and raw counts in the output tables and reports. This step is optional but highly recommended when you expect global changes in chromatin accessibility due to treatments or perturbations.","title":"\ud83d\udcdd Example Configuration"},{"location":"deployment/#dry-run-the-pipeline","text":"Before executing the full analysis and after editing the config.yaml as needed, perform a dry run to visualize the workflow and identify potential issues: aspen -m = dryrun -w = <path_to_output_folder> This step outlines the sequence of tasks (Directed Acyclic Graph - DAG) without actual execution, allowing you to verify the planned operations.","title":"\ud83d\udee0\ufe0f Dry Run the Pipeline"},{"location":"deployment/#execute-the-pipeline","text":"If the dry run output is satisfactory, proceed to execute the pipeline: aspen -m = run -w = <path_to_output_folder> This command submits a master job to the Slurm workload manager, which orchestrates the entire analysis workflow, managing job submissions and monitoring progress. \ud83d\udee0\ufe0f Optional Argument : --singcache or -c : Specify a Singularity cache directory. The default is /data/${USER}/.singularity if available; otherwise, it defaults to ${WORKDIR}/snakemake/.singularity . \ud83d\udca1 Example Command : aspen -m = run -w = <path_to_output_folder> -c /data/ ${ USER } /.singularity This command runs the pipeline with the specified working directory and Singularity cache directory. Note : If deploying on Biowulf, try setting the --singcache to /data/CCBR_Pipeliner/SIFS to reuse the pre-pulled containers and save time.","title":"\ud83d\ude80 Execute the Pipeline"},{"location":"deployment/#monitor-aspen-runs","text":"To monitor the status of your ASPEN pipeline and its associated jobs on a Slurm-managed system, you can utilize the squeue and scontrol commands. The squeue command provides information about jobs in the scheduling queue, while scontrol offers detailed insights into specific jobs. To view all your active and pending jobs, execute: squeue -u $USER --format = \"%.18i %.30j %.11P %.15T %.10r %.10M %.10l %.5D %.5C %.10m %.25b %.8N\" --sort = -S This command lists all jobs submitted by your user account, displaying details such as job IDs, partitions, job names, user names, job states, and the nodes allocated. For more granular information about a specific job, including its child jobs spawned by ASPEN, use the scontrol command: scontrol show job <jobid> Replace with the specific Job ID of interest. This will provide comprehensive details about the job's configuration and status, aiding in effective monitoring and management of your ASPEN pipeline processes. To quickly guage the process of the entire pipeline run: grep \"done $ \" <path_to_output_folder>/snakemake.log","title":"\ud83d\udcca Monitor ASPEN Runs"},{"location":"extra/","text":"Once the ROIs are established, ASPEN generates two distinct count matrices: Tn5 Nicking Sites Count Matrix : This matrix quantifies the frequency of Tn5 transposase insertion events at each ROI. The filtered.bam file (with PCR duplicates and not dedup.bam ) is used for determining Tn5 sites and counting them. The Tn5 transposase preferentially inserts into accessible regions of the chromatin, and the number of insertion events serves as a proxy for chromatin accessibility. By counting these insertion sites, researchers can accurately infer the openness of chromatin regions under different experimental conditions. Read Counts Matrix : This matrix records the number of sequencing reads mapped to each ROI. The filtered.bam file (with PCR duplicates and not dedup.bam ) is used for counting. While Tn5 nicking sites provide a more direct measure of chromatin accessibility, read counts are included in ASPEN as they have been widely used in recent publications. Analyzing both matrices together offers a comprehensive view of chromatin accessibility dynamics.","title":"Extra"},{"location":"introduction/","text":"\ud83d\ude80 Introduction to ATAC-seq \u00b6 ATAC-seq is a powerful technique that enables the identification of open chromatin regions, which are indicative of active regulatory elements such as promoters, enhancers, and transcription factor binding sites. By utilizing the hyperactive Tn5 transposase, ATAC-seq simultaneously fragments DNA and inserts sequencing adapters into accessible regions of the genome. This process, known as tagmentation, allows for the efficient generation of sequencing libraries from small quantities of cells, making ATAC-seq a preferred method for chromatin accessibility studies. The resulting data provide a comprehensive view of the regulatory landscape, facilitating the understanding of gene expression patterns and cellular responses to various stimuli. \ud83e\uddec Spike-in Normalization : To ensure accurate quantification and comparison of chromatin accessibility across samples, ATAC-seq experiments often incorporate spike-in controls. These controls are exogenous DNA or chromatin added in known quantities, enabling normalization of sequencing data to account for technical variability. Spike-in normalization is particularly valuable when comparing samples with differing sequencing depths or experimental conditions, ensuring robust and biologically meaningful interpretations. \ud83d\udee0\ufe0f Containerization : To ensure reproducibility in ATAC-seq data analysis, ASPEN employs Docker containers executed via Singularity on the Biowulf system. This containerized approach encapsulates all software dependencies and environment configurations, enabling consistent and reliable analyses across different computational setups. Utilizing containerization not only streamlines the deployment process but also enhances the reproducibility of results, as the same computational environment can be replicated precisely. This methodology aligns with best practices in bioinformatics, where tools like Docker and Singularity are recommended for maintaining reproducibility in complex data analyses. \u26a0\ufe0f Challenges in ATAC-seq Data Analysis \u00b6 Despite its advantages, ATAC-seq data analysis presents several challenges: \ud83d\udcca Data Complexity : The technique generates large datasets with varying fragment sizes corresponding to nucleosome-free regions, mono-nucleosomes, and multi-nucleosomes, necessitating sophisticated computational tools for accurate interpretation. \u2705 Quality Control : Ensuring high-quality data requires meticulous assessment at multiple stages, including evaluating sequencing quality, fragment size distribution, and enrichment of reads in regulatory regions. \ud83d\udcc8 Peak Calling : Identifying regions of open chromatin (peaks) demands precise computational methods to distinguish true signals from background noise, especially in datasets with low signal-to-noise ratios. \ud83d\udd2c Spike-in Normalization Challenges : While spike-in controls are invaluable for normalization, their implementation requires careful consideration. Variability in spike-in recovery or differences in chromatin accessibility between samples can complicate normalization efforts, necessitating robust experimental design and computational strategies. \ud83d\udd04 Reproducibility : Achieving consistent results across different experiments and conditions is crucial for the reliability of biological interpretations.","title":"Introduction to ATAC-seq"},{"location":"introduction/#introduction-to-atac-seq","text":"ATAC-seq is a powerful technique that enables the identification of open chromatin regions, which are indicative of active regulatory elements such as promoters, enhancers, and transcription factor binding sites. By utilizing the hyperactive Tn5 transposase, ATAC-seq simultaneously fragments DNA and inserts sequencing adapters into accessible regions of the genome. This process, known as tagmentation, allows for the efficient generation of sequencing libraries from small quantities of cells, making ATAC-seq a preferred method for chromatin accessibility studies. The resulting data provide a comprehensive view of the regulatory landscape, facilitating the understanding of gene expression patterns and cellular responses to various stimuli. \ud83e\uddec Spike-in Normalization : To ensure accurate quantification and comparison of chromatin accessibility across samples, ATAC-seq experiments often incorporate spike-in controls. These controls are exogenous DNA or chromatin added in known quantities, enabling normalization of sequencing data to account for technical variability. Spike-in normalization is particularly valuable when comparing samples with differing sequencing depths or experimental conditions, ensuring robust and biologically meaningful interpretations. \ud83d\udee0\ufe0f Containerization : To ensure reproducibility in ATAC-seq data analysis, ASPEN employs Docker containers executed via Singularity on the Biowulf system. This containerized approach encapsulates all software dependencies and environment configurations, enabling consistent and reliable analyses across different computational setups. Utilizing containerization not only streamlines the deployment process but also enhances the reproducibility of results, as the same computational environment can be replicated precisely. This methodology aligns with best practices in bioinformatics, where tools like Docker and Singularity are recommended for maintaining reproducibility in complex data analyses.","title":"\ud83d\ude80 Introduction to ATAC-seq"},{"location":"introduction/#challenges-in-atac-seq-data-analysis","text":"Despite its advantages, ATAC-seq data analysis presents several challenges: \ud83d\udcca Data Complexity : The technique generates large datasets with varying fragment sizes corresponding to nucleosome-free regions, mono-nucleosomes, and multi-nucleosomes, necessitating sophisticated computational tools for accurate interpretation. \u2705 Quality Control : Ensuring high-quality data requires meticulous assessment at multiple stages, including evaluating sequencing quality, fragment size distribution, and enrichment of reads in regulatory regions. \ud83d\udcc8 Peak Calling : Identifying regions of open chromatin (peaks) demands precise computational methods to distinguish true signals from background noise, especially in datasets with low signal-to-noise ratios. \ud83d\udd2c Spike-in Normalization Challenges : While spike-in controls are invaluable for normalization, their implementation requires careful consideration. Variability in spike-in recovery or differences in chromatin accessibility between samples can complicate normalization efforts, necessitating robust experimental design and computational strategies. \ud83d\udd04 Reproducibility : Achieving consistent results across different experiments and conditions is crucial for the reliability of biological interpretations.","title":"\u26a0\ufe0f Challenges in ATAC-seq Data Analysis"},{"location":"limitations/","text":"Limitations of ASPEN \u00b6 Paired-End data required : ASPEN necessitates paired-end sequencing libraries, as its current design does not support single-end data. Future updates aim to incorporate single-end data compatibility. Infrastructure limit : Designed primarily for the BIOWULF High-Performance Computing (HPC) system at the National Institutes of Health (NIH), ASPEN's configuration relies on resources specified in the config.yaml file, which are tailored to the BIOWULF file system. Adapting ASPEN for use on other HPC platforms may require adjustments, such as replicating or generating local reference data, modifying code, and accommodating different job schedulers. Plans are underway to deploy ASPEN on the Frederick Research Computing Environment (FRCE) cluster in Frederick. Footprinting analysis : While ASPEN does not perform footprinting analysis, it is compatible with the CCBR-TOBIAS pipeline, a separate tool designed for this purpose. TOBIAS (Transcription factor Occupancy prediction By Investigation of ATAC-seq Signal) analyzes ATAC-seq data to predict transcription factor occupancy but generates a substantial number of small files. ASPEN's output can serve as direct input for the CCBR_TOBIAS pipeline, facilitating integrated analyses. Genomes supported : Genomes supported is limited to: Genome Assembly Organism Scientific Name hg38 Human Homo sapiens hg19 Human Homo sapiens mm10 Mouse Mus musculus mmul10 Rhesus Monkey Macaca mulatta bosTau9 Domestic Cattle Bos taurus Spike-in genomes supported : Spike-in genomes supported is limited to: Genome Assembly Organism Scientific Name dmelr6.32 Fruit Fly Drosophila melanogaster ecoli_k12 E. coli Escherichia coli","title":"Limitations of ASPEN"},{"location":"limitations/#limitations-of-aspen","text":"Paired-End data required : ASPEN necessitates paired-end sequencing libraries, as its current design does not support single-end data. Future updates aim to incorporate single-end data compatibility. Infrastructure limit : Designed primarily for the BIOWULF High-Performance Computing (HPC) system at the National Institutes of Health (NIH), ASPEN's configuration relies on resources specified in the config.yaml file, which are tailored to the BIOWULF file system. Adapting ASPEN for use on other HPC platforms may require adjustments, such as replicating or generating local reference data, modifying code, and accommodating different job schedulers. Plans are underway to deploy ASPEN on the Frederick Research Computing Environment (FRCE) cluster in Frederick. Footprinting analysis : While ASPEN does not perform footprinting analysis, it is compatible with the CCBR-TOBIAS pipeline, a separate tool designed for this purpose. TOBIAS (Transcription factor Occupancy prediction By Investigation of ATAC-seq Signal) analyzes ATAC-seq data to predict transcription factor occupancy but generates a substantial number of small files. ASPEN's output can serve as direct input for the CCBR_TOBIAS pipeline, facilitating integrated analyses. Genomes supported : Genomes supported is limited to: Genome Assembly Organism Scientific Name hg38 Human Homo sapiens hg19 Human Homo sapiens mm10 Mouse Mus musculus mmul10 Rhesus Monkey Macaca mulatta bosTau9 Domestic Cattle Bos taurus Spike-in genomes supported : Spike-in genomes supported is limited to: Genome Assembly Organism Scientific Name dmelr6.32 Fruit Fly Drosophila melanogaster ecoli_k12 E. coli Escherichia coli","title":"Limitations of ASPEN"},{"location":"log/","text":"Creation of test dataset \u00b6 Using the D4_Meso_iCre_Dox and iCre_D0 samples from the ccbr872 mouse dataset: Select 2 replicates for each group .. total samples = 4 extract readids from the chr19:10000000-20000000 region using: % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/iCre_D0_1.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq > iCre_D0_1.chr19.readids & % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/iCre_D0_2.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq > iCre_D0_2.chr19.readids & % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/D4_Meso_iCre_Dox_1.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq > D4_Meso_iCre_Dox_1.chr19.readids & % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/D4_Meso_iCre_Dox_2.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq > D4_Meso_iCre_Dox_2.chr19.readids & create subsampled fastq files using these readids: % cd /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq % python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq iCre_D0_1.R1.fastq.gz --infq2 iCre_D0_1.R2.fastq.gz --outfq iCre_D0_1.subset.R1.fastq.gz --outfq2 iCre_D0_1.subset.R2.fastq.gz --readids iCre_D0_1.chr19.readids % python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq iCre_D0_2.R1.fastq.gz --infq2 iCre_D0_2.R2.fastq.gz --outfq iCre_D0_2.subset.R1.fastq.gz --outfq2 iCre_D0_2.subset.R2.fastq.gz --readids iCre_D0_2.chr19.readids % python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq D4_Meso_iCre_Dox_1.R1.fastq.gz --infq2 D4_Meso_iCre_Dox_1.R2.fastq.gz --outfq D4_Meso_iCre_Dox_1.subset.R1.fastq.gz --outfq2 D4_Meso_iCre_Dox_1.subset.R2.fastq.gz --readids D4_Meso_iCre_Dox_1.chr19.readids % python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq D4_Meso_iCre_Dox_2.R1.fastq.gz --infq2 D4_Meso_iCre_Dox_2.R2.fastq.gz --outfq D4_Meso_iCre_Dox_2.subset.R1.fastq.gz --outfq2 D4_Meso_iCre_Dox_2.subset.R2.fastq.gz --readids D4_Meso_iCre_Dox_2.chr19.readids Now, the samples.tsv will look something like this: sampleName path_to_R1_fastq path_to_R2_fastq D4_Meso_iCre_Dox_1 /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_1.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_1.subset.R2.fastq.pai red.fq.gz D4_Meso_iCre_Dox_2 /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_2.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_2.subset.R2.fastq.pai red.fq.gz iCre_D0_1 /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_1.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_1.subset.R2.fastq.paired.fq.gz iCre_D0_2 /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_2.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_2.subset.R2.fastq.paired.fq.gz","title":"Log"},{"location":"log/#creation-of-test-dataset","text":"Using the D4_Meso_iCre_Dox and iCre_D0 samples from the ccbr872 mouse dataset: Select 2 replicates for each group .. total samples = 4 extract readids from the chr19:10000000-20000000 region using: % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/iCre_D0_1.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq > iCre_D0_1.chr19.readids & % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/iCre_D0_2.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq > iCre_D0_2.chr19.readids & % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/D4_Meso_iCre_Dox_1.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq > D4_Meso_iCre_Dox_1.chr19.readids & % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/D4_Meso_iCre_Dox_2.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq > D4_Meso_iCre_Dox_2.chr19.readids & create subsampled fastq files using these readids: % cd /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq % python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq iCre_D0_1.R1.fastq.gz --infq2 iCre_D0_1.R2.fastq.gz --outfq iCre_D0_1.subset.R1.fastq.gz --outfq2 iCre_D0_1.subset.R2.fastq.gz --readids iCre_D0_1.chr19.readids % python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq iCre_D0_2.R1.fastq.gz --infq2 iCre_D0_2.R2.fastq.gz --outfq iCre_D0_2.subset.R1.fastq.gz --outfq2 iCre_D0_2.subset.R2.fastq.gz --readids iCre_D0_2.chr19.readids % python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq D4_Meso_iCre_Dox_1.R1.fastq.gz --infq2 D4_Meso_iCre_Dox_1.R2.fastq.gz --outfq D4_Meso_iCre_Dox_1.subset.R1.fastq.gz --outfq2 D4_Meso_iCre_Dox_1.subset.R2.fastq.gz --readids D4_Meso_iCre_Dox_1.chr19.readids % python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq D4_Meso_iCre_Dox_2.R1.fastq.gz --infq2 D4_Meso_iCre_Dox_2.R2.fastq.gz --outfq D4_Meso_iCre_Dox_2.subset.R1.fastq.gz --outfq2 D4_Meso_iCre_Dox_2.subset.R2.fastq.gz --readids D4_Meso_iCre_Dox_2.chr19.readids Now, the samples.tsv will look something like this: sampleName path_to_R1_fastq path_to_R2_fastq D4_Meso_iCre_Dox_1 /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_1.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_1.subset.R2.fastq.pai red.fq.gz D4_Meso_iCre_Dox_2 /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_2.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_2.subset.R2.fastq.pai red.fq.gz iCre_D0_1 /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_1.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_1.subset.R2.fastq.paired.fq.gz iCre_D0_2 /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_2.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_2.subset.R2.fastq.paired.fq.gz","title":"Creation of test dataset"},{"location":"outputs/","text":"\ud83d\ude80 ASPEN Outputs \u00b6 \ud83d\udcc2 Workdir \u00b6 The workdir which is supplied as -w while running aspen init , dryrun and run commands will contain the following files: WORKDIR \u251c\u2500\u2500 cluster.json \u251c\u2500\u2500 config.yaml \u251c\u2500\u2500 contrasts.tsv \u251c\u2500\u2500 dryrun_git_commit.txt \u251c\u2500\u2500 dryrun.log \u251c\u2500\u2500 fastqs \u251c\u2500\u2500 logs \u251c\u2500\u2500 results \u251c\u2500\u2500 run_git_commit.txt \u251c\u2500\u2500 runinfo.yaml \u251c\u2500\u2500 runslurm_snakemake_report.html \u251c\u2500\u2500 sampleinfo.txt \u251c\u2500\u2500 samples.tsv \u251c\u2500\u2500 scripts \u251c\u2500\u2500 slurm-XXXXXXX.out \u251c\u2500\u2500 snakemake.log \u251c\u2500\u2500 snakemake.log.jobby \u251c\u2500\u2500 snakemake.log.jobby.short \u251c\u2500\u2500 snakemake.stats \u251c\u2500\u2500 submit_script.sbatch \u2514\u2500\u2500 tools.yaml Here are more details about these files: File File Type Mode ( -m ) When This File is Created/Overwritten Description cluster.json JSON init Defines cluster resources per snakemake rule; this file can be edited to override default computate resource allocations per snakemake rule config.yaml YAML init; can be edited later Configurable parameters for this specific run contrasts.tsv TSV Needs to be added in after init List of contrasts to run, one per line; has no header dryrun_git_commit.txt TXT dryrun The git commit hash of the version of ASPEN used at dryrun dryrun.log TXT dryrun Log from -m=dryrun fastqs FOLDER dryrun Folder containing symlinks to raw data logs FOLDER dryrun Folder containing all logs including Slurm .out and .err files. Also contains older timestamped runinfo.yaml and snakemake.stats files. results FOLDER Created at dryrun but populated during run Main outputs folder runinfo.yaml YAML After completion of run Metadata about the run executor, etc. runslurm_snakemake_report.html HTML After completion of run HTML report including DAG and resource utilization sampleinfo.txt TXT dryrun, run Tab-delimited mappings between replicateNames and sampleNames samples.tsv TSV init; can be edited later Tab-delimited manifest with replicateName , sampleName , path_to_R1_fastq , path_to_R2_fastq . This file has a header. scripts FOLDER init Folder keeps local copy of scripts called by various rules run_git_commit.txt TXT run The git commit hash of the version of ASPEN used at run slurm-XXXXXXX.out TXT run Slurm .out file for the master job snakemake.log TXT run Snakemake .log file for the master job; older copies timestamped and moved into logs folder snakemake.stats JSON run per rule runtime stats submit_script.sbatch TXT run Slurm script to kickstart the main Snakemake job tools.yaml YAML run YAML containing the version of tools used in the pipeline (obsolete; was used to load specific module versions prior to moving over to Docker/Singularity containers) \ud83d\udcca results folder \u00b6 The results directory contains the actual output files. Below are the folders that you may find within it. WORKDIR \u251c\u2500\u2500 results \u251c\u2500\u2500 alignment \u2502 \u251c\u2500\u2500 dedupBam \u2502 \u251c\u2500\u2500 filteredBam \u2502 \u251c\u2500\u2500 qsortedBam \u2502 \u2514\u2500\u2500 tagAlign \u251c\u2500\u2500 peaks \u2502 \u251c\u2500\u2500 genrich \u2502 \u2502 \u251c\u2500\u2500 DiffATAC \u2502 \u2502 \u2502 \u251c\u2500\u2500 reads \u2502 \u2502 \u2502 \u2514\u2500\u2500 tn5sites \u2502 \u2502 \u2514\u2500\u2500 fixed_width \u2502 \u2514\u2500\u2500 macs2 \u2502 \u251c\u2500\u2500 DiffATAC \u2502 \u2502 \u251c\u2500\u2500 reads \u2502 \u2502 \u2514\u2500\u2500 tn5sites \u2502 \u2514\u2500\u2500 fixed_width \u251c\u2500\u2500 QC \u2502 \u251c\u2500\u2500 fastqc \u2502 \u251c\u2500\u2500 fld \u2502 \u251c\u2500\u2500 FQscreen \u2502 \u251c\u2500\u2500 frip \u2502 \u251c\u2500\u2500 multiqc_data \u2502 \u251c\u2500\u2500 peak_annotation \u2502 \u251c\u2500\u2500 preseq \u2502 \u2514\u2500\u2500 tss \u251c\u2500\u2500 spikein \u2502 \u251c\u2500\u2500 <sample_1> \u2502 \u251c\u2500\u2500 <sample_2> \u2502 \u251c\u2500\u2500 <sample_3> \u2502 \u2502 ... \u2502 \u2514\u2500\u2500 <sample_n> \u251c\u2500\u2500 tmp \u2502 \u251c\u2500\u2500 BL \u2502 \u251c\u2500\u2500 genrichReads \u2502 \u2514\u2500\u2500 trim \u2514\u2500\u2500 visualization \u251c\u2500\u2500 reads_bam \u251c\u2500\u2500 reads_bed \u251c\u2500\u2500 reads_bigwig \u251c\u2500\u2500 tn5sites_bam \u2514\u2500\u2500 tn5sites_bigwig Content details: Folder SubFolder Description alignment qsortedBam - Query sorted Bowtie2 alignments in BAM format. - Excludes unmapped and platform/vendor quality failing reads. - Used for Genrich peak calling. alignment filteredBam - Filtered BAM files after excluding non-primary, supplementary, and MAPQ <=5 alignments. - Used for counting reads/tn5 nicks. - Derived from qsortedBam . alignment dedupBam - Deduplicated filtered BAM files. - PCR or optical duplicates marked with PicardTools and excluded. - Can be used downstream with CCBR_TOBIAS pipeline. - Derived from filteredBam . alignment tagAlign - tagAlign.gz files used for MACS2 peak calling. - Derived from dedupBam . peaks genrich & macs - Genrich/MACS2 peak calls (raw, consensus, fixed-width). - Contains ROI files with Diff-ATAC results if contrasts.tsv is provided. - Calculated with DESeq2 using both read counts and tn5 nicking sites in ROI. QC various - Flagstats. - Dupmetrics. - Read counts. - Motif enrichments. - FLD stats. - Fqscreen. - FRiP. - ChIPSeeker results. - TSS enrichments. - Preseq. - Homer/AME motif enrichments. - MultiQC. QC peak_annotation detailed peak annotations described below spikein 1 folder per sample - Per sample spike-in counts. - Overall scaling factors table. tmp various - Can be deleted. - Blacklist index. - Intermediate FASTQs. - Genrich output reads. visualization reads_bam - Tn5 nick adjusted reads in BAM format. - Derived from filteredBam . visualization reads_bed - Tn5 nick adjusted reads in BED format. - Derived from reads_bam . - Can be used by ChromVar. visualization reads_bigwig - Tn5 nick adjusted reads in BIGWIG format. - Scaled using spike-in scaling factors if present. - Derived from reads_bam . visualization tn5sites_bam - Tn5 nicking sites in BAM format. - Derived from filteredBam . visualization tn5sites_bigwig - Tn5 nicking sites in BIGWIG format. - Scaled using spike-in scaling factors if present. - Derived from tn5sites_bam . Note BAM files from dedupBam can be used for downstream footprinting analysis using CCBR_TOBIAS pipeline Note bamCompare from deeptools can be run to compare BAMs from dedupBam for comprehensive BAM comparisons. Note BAM files from dedupBam can also be converted to BED format and processed with chromVAR to identify variability in motif accessibility across samples and assess differentially active transcription factors from the JASPAR database. Peak Annotation folder \u00b6 This folder will contain ChIPseeker results for: individual replicate *.narrowPeak files *.consensus.bed files *.fixed_width.consensus.narrowPeak files The QC folder contains the multiqc_report.html file which provides a comprehensive summary of the quality control metrics across all samples, including read quality, duplication rates, and other relevant statistics. This report aggregates results from various QC tools such as FastQC, FastqScreen, FLD, TSS enrichment, Peak Annotations, and others, presenting them in an easy-to-read format with interactive plots and tables. It helps in quickly identifying any issues with the sequencing data and ensures that the data quality is sufficient for downstream analysis. File Description *.narrowPeak.annotated.gz peak calls annotated using ChIPseeker, gzipped *.narrowPeak.annotated.distribution annotation bins : - 3'UTR : No. of peaks in the 3' untranslated region. - 5'UTR : No. of peaks in the 5' untranslated region. - Distal Intergenic : No. of peaks in distal intergenic regions. - Downstream (<1kb) : No. of peaks annotated downstream within 1kb. - Downstream (1-2kb) : No. of peaks annotated downstream between 1-2kb. - Downstream (2-3kb) : No. of peaks annotated downstream between 2-3kb. - Promoter (<=1kb) : No. of peaks in promoters within 1kb. - Promoter (1-2kb) : No. of peaks in promoters between 1-2kb. - Exon : No. of peaks in exonic regions. *.narrowPeak.annotated_summary More stats on each of the above bins .. like: - medianWidth - medianpValue - medianqValue *.narrowPeak.genelist ensemblID and gene symbols of genes with peaks in their promoter regions (including 5' UTR) MACS2 output folder \u00b6 For a typical 2 sample analysis with 2 replicates each this folder should look like this: WORKDIR \u251c\u2500\u2500 results \u251c\u2500\u2500 peaks \u2514\u2500\u2500 macs2 \u251c\u2500\u2500 sample1 \u2502 \u251c\u2500\u2500 sample1_replicate1.macs2.narrowPeak \u2502 \u251c\u2500\u2500 sample1_replicate1.macs2.narrowPeak_motif_enrichment \u2502 \u2502 \u251c\u2500\u2500 ame_results.txt \u2502 \u2502 \u251c\u2500\u2500 background.fa \u2502 \u2502 \u251c\u2500\u2500 knownResults \u2502 \u2502 \u251c\u2500\u2500 knownResults.html \u2502 \u2502 \u251c\u2500\u2500 knownResults.txt \u2502 \u2502 \u251c\u2500\u2500 motifFindingParameters.txt \u2502 \u2502 \u251c\u2500\u2500 seq.autonorm.tsv \u2502 \u2502 \u2514\u2500\u2500 target.fa \u2502 \u251c\u2500\u2500 sample1_replicate1.macs2.unfiltered.narrowPeak \u2502 \u251c\u2500\u2500 sample1_replicate2.macs2.narrowPeak \u2502 \u251c\u2500\u2500 sample1_replicate2.macs2.narrowPeak_motif_enrichment \u2502 \u2502 \u251c\u2500\u2500 ame_results.txt \u2502 \u2502 \u251c\u2500\u2500 background.fa \u2502 \u2502 \u251c\u2500\u2500 knownResults \u2502 \u2502 \u251c\u2500\u2500 knownResults.html \u2502 \u2502 \u251c\u2500\u2500 knownResults.txt \u2502 \u2502 \u251c\u2500\u2500 motifFindingParameters.txt \u2502 \u2502 \u251c\u2500\u2500 seq.autonorm.tsv \u2502 \u2502 \u2514\u2500\u2500 target.fa \u2502 \u251c\u2500\u2500 sample1_replicate2.macs2.unfiltered.narrowPeak \u2502 \u251c\u2500\u2500 sample1.macs2.consensus.bed \u2502 \u251c\u2500\u2500 sample1.macs2.consensus.bed_motif_enrichment \u2502 \u2502 \u251c\u2500\u2500 ame_results.txt \u2502 \u2502 \u251c\u2500\u2500 background.fa \u2502 \u2502 \u251c\u2500\u2500 knownResults \u2502 \u2502 \u251c\u2500\u2500 knownResults.html \u2502 \u2502 \u251c\u2500\u2500 knownResults.txt \u2502 \u2502 \u251c\u2500\u2500 motifFindingParameters.txt \u2502 \u2502 \u251c\u2500\u2500 seq.autonorm.tsv \u2502 \u2502 \u2514\u2500\u2500 target.fa \u2502 \u251c\u2500\u2500 sample1.macs2.pooled.narrowPeak \u2502 \u251c\u2500\u2500 sample1.macs2.pooled_summits.bed \u2502 \u2514\u2500\u2500 sample1.macs2.pooled.unfiltered.narrowPeak \u251c\u2500\u2500 sample1.consensus.macs2.peakfiles \u251c\u2500\u2500 sample1.replicate.macs2.peakfiles \u251c\u2500\u2500 DiffATAC \u2502 \u251c\u2500\u2500 reads \u2502 \u2502 \u251c\u2500\u2500 all_diff_atacs.html \u2502 \u2502 \u251c\u2500\u2500 all_diff_atacs.tsv \u2502 \u2502 \u251c\u2500\u2500 degs.done \u2502 \u2502 \u251c\u2500\u2500 sample2_vs_sample1.html \u2502 \u2502 \u2514\u2500\u2500 sample2_vs_sample1.tsv \u2502 \u2514\u2500\u2500 tn5sites \u2502 \u251c\u2500\u2500 all_diff_atacs.html \u2502 \u251c\u2500\u2500 all_diff_atacs.tsv \u2502 \u251c\u2500\u2500 degs.done \u2502 \u251c\u2500\u2500 sample2_vs_sample1.html \u2502 \u2514\u2500\u2500 sample2_vs_sample1.tsv \u251c\u2500\u2500 sample2 \u2502 \u251c\u2500\u2500 sample2_replicate1.macs2.narrowPeak \u2502 \u251c\u2500\u2500 sample2_replicate1.macs2.narrowPeak_motif_enrichment \u2502 \u2502 \u251c\u2500\u2500 ame_results.txt \u2502 \u2502 \u251c\u2500\u2500 background.fa \u2502 \u2502 \u251c\u2500\u2500 knownResults \u2502 \u2502 \u251c\u2500\u2500 knownResults.html \u2502 \u2502 \u251c\u2500\u2500 knownResults.txt \u2502 \u2502 \u251c\u2500\u2500 motifFindingParameters.txt \u2502 \u2502 \u251c\u2500\u2500 seq.autonorm.tsv \u2502 \u2502 \u2514\u2500\u2500 target.fa \u2502 \u251c\u2500\u2500 sample2_replicate1.macs2.unfiltered.narrowPeak \u2502 \u251c\u2500\u2500 sample2_replicate2.macs2.narrowPeak \u2502 \u251c\u2500\u2500 sample2_replicate2.macs2.narrowPeak_motif_enrichment \u2502 \u2502 \u251c\u2500\u2500 ame_results.txt \u2502 \u2502 \u251c\u2500\u2500 background.fa \u2502 \u2502 \u251c\u2500\u2500 knownResults \u2502 \u2502 \u251c\u2500\u2500 knownResults.html \u2502 \u2502 \u251c\u2500\u2500 knownResults.txt \u2502 \u2502 \u251c\u2500\u2500 motifFindingParameters.txt \u2502 \u2502 \u251c\u2500\u2500 seq.autonorm.tsv \u2502 \u2502 \u2514\u2500\u2500 target.fa \u2502 \u251c\u2500\u2500 sample2_replicate2.macs2.unfiltered.narrowPeak \u2502 \u251c\u2500\u2500 sample2.macs2.consensus.bed \u2502 \u251c\u2500\u2500 sample2.macs2.consensus.bed_motif_enrichment \u2502 \u2502 \u251c\u2500\u2500 ame_results.txt \u2502 \u2502 \u251c\u2500\u2500 background.fa \u2502 \u2502 \u251c\u2500\u2500 knownResults \u2502 \u2502 \u251c\u2500\u2500 knownResults.html \u2502 \u2502 \u251c\u2500\u2500 knownResults.txt \u2502 \u2502 \u251c\u2500\u2500 motifFindingParameters.txt \u2502 \u2502 \u251c\u2500\u2500 seq.autonorm.tsv \u2502 \u2502 \u2514\u2500\u2500 target.fa \u2502 \u251c\u2500\u2500 sample2.macs2.pooled.narrowPeak \u2502 \u251c\u2500\u2500 sample2.macs2.pooled_summits.bed \u2502 \u2514\u2500\u2500 sample2.macs2.pooled.unfiltered.narrowPeak \u251c\u2500\u2500 sample2.consensus.macs2.peakfiles \u251c\u2500\u2500 sample2.replicate.macs2.peakfiles \u2514\u2500\u2500 fixed_width \u251c\u2500\u2500 sample1_replicate1.macs2.fixed_width.narrowPeak \u251c\u2500\u2500 sample1_replicate2.macs2.fixed_width.narrowPeak \u251c\u2500\u2500 sample1.fixed_width.consensus.narrowPeak \u251c\u2500\u2500 sample1.renormalized.fixed_width.consensus.narrowPeak \u251c\u2500\u2500 sample1.renormalized.fixed_width.consensus.narrowPeak.annotated.gz \u251c\u2500\u2500 counts \u2502 \u251c\u2500\u2500 ROI.macs2.reads_counts.tsv \u2502 \u2514\u2500\u2500 ROI.macs2.tn5sites_counts.tsv \u251c\u2500\u2500 sample2_replicate1.macs2.fixed_width.narrowPeak \u251c\u2500\u2500 sample2_replicate2.macs2.fixed_width.narrowPeak \u251c\u2500\u2500 sample2.fixed_width.consensus.narrowPeak \u251c\u2500\u2500 sample2.renormalized.fixed_width.consensus.narrowPeak \u251c\u2500\u2500 sample2.renormalized.fixed_width.consensus.narrowPeak.annotated.gz \u251c\u2500\u2500 ROI.macs2.bed \u251c\u2500\u2500 ROI.macs2.bed.annotated.gz \u251c\u2500\u2500 ROI.macs2.bed.annotated.gz.gz \u251c\u2500\u2500 ROI.macs2.bed.annotation_distribution \u251c\u2500\u2500 ROI.macs2.bed.annotation_summary \u251c\u2500\u2500 ROI.macs2.bed.genelist \u251c\u2500\u2500 ROI.macs2.gtf \u251c\u2500\u2500 ROI.macs2.narrowPeak \u251c\u2500\u2500 ROI.macs2.renormalized.narrowPeak \u2514\u2500\u2500 Rplots.pdf Some of the key output files are: File Description *.macs2.narrowPeak peak calls from MACS2 filtered by q-value for each samples each replicate *.macs2.unfiltered.narrowPeak peak calls from MACS2 (unfiltered) for each samples each replicate *.narrowPeak_motif_enrichment/ame_results.txt motif enrichment results from AME tool from MEME suite using HOCOMOCO v11 database *.narrowPeak_motif_enrichment/knownResults.txt motif enrichment results using HOMER with HOCOMOCO v11 database *.macs2.consensus.bed consensus peak call between multiple replicates of each sample. Note: consensus bed annotations are located in QC/peak_annotations DiffATAC/reads folder containing differential open chromatin results: - computated using read counts in MACS2 regions of interest (ROIs) - all_diff_atacs.html HTML report aggregated across all contrasts from contrasts.tsv - all_diff_atacs.tsv DESeq2 results in TSV format aggregated across all contrasts from contrasts.tsv - HTML and TSV file each per contrast in contrasts.tsv DiffATAC/tn5sites folder containing differential open chromatin results: - computated using Tn5 nicking site counts in MACS2 regions of interest (ROIs) - all_diff_atacs.html HTML report aggregated across all contrasts from contrasts.tsv - all_diff_atacs.tsv DESeq2 results in TSV format aggregated across all contrasts from contrasts.tsv - HTML and TSV file each per contrast in contrasts.tsv fixed_width fixed_width can be set in config.yaml to create peaks of a user defined fixed width (default 500bp). This folder contains: - individual replicate *.fixed_width.narrowPeak files - *.renormalized.fixed_width.consensus.narrowPeak per sample; Corces et. al. method is used for consensus calling; used to generate MACS2 regions of interest (ROI) peaks which are used to generate a reads or Tn5 sites counts matrix for DESeq2 - ROI related files: ROI.macs2.bed , ROI.macs2.bed.annotated.gz , ROI.macs2.annotation_summary , ROI.macs2.annotation_distribution fixed_width/counts/ROI.macs2.read_counts.tsv read counts in MACS2 ROIs using featureCounts fixed_width/counts/ROI.reads_scaled_counts.tsv ROI.macs2.read_counts.tsv scaled using spike-in scaling factors fixed_width/counts/ROI.tn5sites_counts.tsv Tn5 nicking site counts in MACS2 ROIs using featureCounts fixed_width/counts/ROI.tn5sites_scaled_counts.tsv ROI.macs2.tn5sites_counts.tsv scaled using spike-in scaling factors Genrich output folder \u00b6 For a typical 2 sample analysis with 2 replicates each this folder should look like very similar to the MACS2 output structure described above. logs folder \u00b6 This directory contains all .err and .out log files generated by SLURM for jobs submitted via Snakemake. Each file follows a consistent naming convention: <SLURM_JOB_ID of master/head job>.<SLURM_JOB_ID of child job>.<Snakemake Rule Name>.< wildcard1_name = wildcard1_value,wildcard2_name = wildcard2_value>.<out or err> This structure is particularly useful for troubleshooting and debugging, especially when the SLURM job IDs of failed jobs are known. By examining the corresponding .err or .out files, users can efficiently identify the source of errors within specific Snakemake rules and wildcards. DISCLAIMER: This folder hierarchy is significantly different than v1.0.6 and is subject to change with subsequent versions.","title":"ASPEN Output"},{"location":"outputs/#aspen-outputs","text":"","title":"\ud83d\ude80 ASPEN Outputs"},{"location":"outputs/#workdir","text":"The workdir which is supplied as -w while running aspen init , dryrun and run commands will contain the following files: WORKDIR \u251c\u2500\u2500 cluster.json \u251c\u2500\u2500 config.yaml \u251c\u2500\u2500 contrasts.tsv \u251c\u2500\u2500 dryrun_git_commit.txt \u251c\u2500\u2500 dryrun.log \u251c\u2500\u2500 fastqs \u251c\u2500\u2500 logs \u251c\u2500\u2500 results \u251c\u2500\u2500 run_git_commit.txt \u251c\u2500\u2500 runinfo.yaml \u251c\u2500\u2500 runslurm_snakemake_report.html \u251c\u2500\u2500 sampleinfo.txt \u251c\u2500\u2500 samples.tsv \u251c\u2500\u2500 scripts \u251c\u2500\u2500 slurm-XXXXXXX.out \u251c\u2500\u2500 snakemake.log \u251c\u2500\u2500 snakemake.log.jobby \u251c\u2500\u2500 snakemake.log.jobby.short \u251c\u2500\u2500 snakemake.stats \u251c\u2500\u2500 submit_script.sbatch \u2514\u2500\u2500 tools.yaml Here are more details about these files: File File Type Mode ( -m ) When This File is Created/Overwritten Description cluster.json JSON init Defines cluster resources per snakemake rule; this file can be edited to override default computate resource allocations per snakemake rule config.yaml YAML init; can be edited later Configurable parameters for this specific run contrasts.tsv TSV Needs to be added in after init List of contrasts to run, one per line; has no header dryrun_git_commit.txt TXT dryrun The git commit hash of the version of ASPEN used at dryrun dryrun.log TXT dryrun Log from -m=dryrun fastqs FOLDER dryrun Folder containing symlinks to raw data logs FOLDER dryrun Folder containing all logs including Slurm .out and .err files. Also contains older timestamped runinfo.yaml and snakemake.stats files. results FOLDER Created at dryrun but populated during run Main outputs folder runinfo.yaml YAML After completion of run Metadata about the run executor, etc. runslurm_snakemake_report.html HTML After completion of run HTML report including DAG and resource utilization sampleinfo.txt TXT dryrun, run Tab-delimited mappings between replicateNames and sampleNames samples.tsv TSV init; can be edited later Tab-delimited manifest with replicateName , sampleName , path_to_R1_fastq , path_to_R2_fastq . This file has a header. scripts FOLDER init Folder keeps local copy of scripts called by various rules run_git_commit.txt TXT run The git commit hash of the version of ASPEN used at run slurm-XXXXXXX.out TXT run Slurm .out file for the master job snakemake.log TXT run Snakemake .log file for the master job; older copies timestamped and moved into logs folder snakemake.stats JSON run per rule runtime stats submit_script.sbatch TXT run Slurm script to kickstart the main Snakemake job tools.yaml YAML run YAML containing the version of tools used in the pipeline (obsolete; was used to load specific module versions prior to moving over to Docker/Singularity containers)","title":"\ud83d\udcc2 Workdir"},{"location":"outputs/#results-folder","text":"The results directory contains the actual output files. Below are the folders that you may find within it. WORKDIR \u251c\u2500\u2500 results \u251c\u2500\u2500 alignment \u2502 \u251c\u2500\u2500 dedupBam \u2502 \u251c\u2500\u2500 filteredBam \u2502 \u251c\u2500\u2500 qsortedBam \u2502 \u2514\u2500\u2500 tagAlign \u251c\u2500\u2500 peaks \u2502 \u251c\u2500\u2500 genrich \u2502 \u2502 \u251c\u2500\u2500 DiffATAC \u2502 \u2502 \u2502 \u251c\u2500\u2500 reads \u2502 \u2502 \u2502 \u2514\u2500\u2500 tn5sites \u2502 \u2502 \u2514\u2500\u2500 fixed_width \u2502 \u2514\u2500\u2500 macs2 \u2502 \u251c\u2500\u2500 DiffATAC \u2502 \u2502 \u251c\u2500\u2500 reads \u2502 \u2502 \u2514\u2500\u2500 tn5sites \u2502 \u2514\u2500\u2500 fixed_width \u251c\u2500\u2500 QC \u2502 \u251c\u2500\u2500 fastqc \u2502 \u251c\u2500\u2500 fld \u2502 \u251c\u2500\u2500 FQscreen \u2502 \u251c\u2500\u2500 frip \u2502 \u251c\u2500\u2500 multiqc_data \u2502 \u251c\u2500\u2500 peak_annotation \u2502 \u251c\u2500\u2500 preseq \u2502 \u2514\u2500\u2500 tss \u251c\u2500\u2500 spikein \u2502 \u251c\u2500\u2500 <sample_1> \u2502 \u251c\u2500\u2500 <sample_2> \u2502 \u251c\u2500\u2500 <sample_3> \u2502 \u2502 ... \u2502 \u2514\u2500\u2500 <sample_n> \u251c\u2500\u2500 tmp \u2502 \u251c\u2500\u2500 BL \u2502 \u251c\u2500\u2500 genrichReads \u2502 \u2514\u2500\u2500 trim \u2514\u2500\u2500 visualization \u251c\u2500\u2500 reads_bam \u251c\u2500\u2500 reads_bed \u251c\u2500\u2500 reads_bigwig \u251c\u2500\u2500 tn5sites_bam \u2514\u2500\u2500 tn5sites_bigwig Content details: Folder SubFolder Description alignment qsortedBam - Query sorted Bowtie2 alignments in BAM format. - Excludes unmapped and platform/vendor quality failing reads. - Used for Genrich peak calling. alignment filteredBam - Filtered BAM files after excluding non-primary, supplementary, and MAPQ <=5 alignments. - Used for counting reads/tn5 nicks. - Derived from qsortedBam . alignment dedupBam - Deduplicated filtered BAM files. - PCR or optical duplicates marked with PicardTools and excluded. - Can be used downstream with CCBR_TOBIAS pipeline. - Derived from filteredBam . alignment tagAlign - tagAlign.gz files used for MACS2 peak calling. - Derived from dedupBam . peaks genrich & macs - Genrich/MACS2 peak calls (raw, consensus, fixed-width). - Contains ROI files with Diff-ATAC results if contrasts.tsv is provided. - Calculated with DESeq2 using both read counts and tn5 nicking sites in ROI. QC various - Flagstats. - Dupmetrics. - Read counts. - Motif enrichments. - FLD stats. - Fqscreen. - FRiP. - ChIPSeeker results. - TSS enrichments. - Preseq. - Homer/AME motif enrichments. - MultiQC. QC peak_annotation detailed peak annotations described below spikein 1 folder per sample - Per sample spike-in counts. - Overall scaling factors table. tmp various - Can be deleted. - Blacklist index. - Intermediate FASTQs. - Genrich output reads. visualization reads_bam - Tn5 nick adjusted reads in BAM format. - Derived from filteredBam . visualization reads_bed - Tn5 nick adjusted reads in BED format. - Derived from reads_bam . - Can be used by ChromVar. visualization reads_bigwig - Tn5 nick adjusted reads in BIGWIG format. - Scaled using spike-in scaling factors if present. - Derived from reads_bam . visualization tn5sites_bam - Tn5 nicking sites in BAM format. - Derived from filteredBam . visualization tn5sites_bigwig - Tn5 nicking sites in BIGWIG format. - Scaled using spike-in scaling factors if present. - Derived from tn5sites_bam . Note BAM files from dedupBam can be used for downstream footprinting analysis using CCBR_TOBIAS pipeline Note bamCompare from deeptools can be run to compare BAMs from dedupBam for comprehensive BAM comparisons. Note BAM files from dedupBam can also be converted to BED format and processed with chromVAR to identify variability in motif accessibility across samples and assess differentially active transcription factors from the JASPAR database.","title":"\ud83d\udcca results folder"},{"location":"outputs/#peak-annotation-folder","text":"This folder will contain ChIPseeker results for: individual replicate *.narrowPeak files *.consensus.bed files *.fixed_width.consensus.narrowPeak files The QC folder contains the multiqc_report.html file which provides a comprehensive summary of the quality control metrics across all samples, including read quality, duplication rates, and other relevant statistics. This report aggregates results from various QC tools such as FastQC, FastqScreen, FLD, TSS enrichment, Peak Annotations, and others, presenting them in an easy-to-read format with interactive plots and tables. It helps in quickly identifying any issues with the sequencing data and ensures that the data quality is sufficient for downstream analysis. File Description *.narrowPeak.annotated.gz peak calls annotated using ChIPseeker, gzipped *.narrowPeak.annotated.distribution annotation bins : - 3'UTR : No. of peaks in the 3' untranslated region. - 5'UTR : No. of peaks in the 5' untranslated region. - Distal Intergenic : No. of peaks in distal intergenic regions. - Downstream (<1kb) : No. of peaks annotated downstream within 1kb. - Downstream (1-2kb) : No. of peaks annotated downstream between 1-2kb. - Downstream (2-3kb) : No. of peaks annotated downstream between 2-3kb. - Promoter (<=1kb) : No. of peaks in promoters within 1kb. - Promoter (1-2kb) : No. of peaks in promoters between 1-2kb. - Exon : No. of peaks in exonic regions. *.narrowPeak.annotated_summary More stats on each of the above bins .. like: - medianWidth - medianpValue - medianqValue *.narrowPeak.genelist ensemblID and gene symbols of genes with peaks in their promoter regions (including 5' UTR)","title":"Peak Annotation folder"},{"location":"outputs/#macs2-output-folder","text":"For a typical 2 sample analysis with 2 replicates each this folder should look like this: WORKDIR \u251c\u2500\u2500 results \u251c\u2500\u2500 peaks \u2514\u2500\u2500 macs2 \u251c\u2500\u2500 sample1 \u2502 \u251c\u2500\u2500 sample1_replicate1.macs2.narrowPeak \u2502 \u251c\u2500\u2500 sample1_replicate1.macs2.narrowPeak_motif_enrichment \u2502 \u2502 \u251c\u2500\u2500 ame_results.txt \u2502 \u2502 \u251c\u2500\u2500 background.fa \u2502 \u2502 \u251c\u2500\u2500 knownResults \u2502 \u2502 \u251c\u2500\u2500 knownResults.html \u2502 \u2502 \u251c\u2500\u2500 knownResults.txt \u2502 \u2502 \u251c\u2500\u2500 motifFindingParameters.txt \u2502 \u2502 \u251c\u2500\u2500 seq.autonorm.tsv \u2502 \u2502 \u2514\u2500\u2500 target.fa \u2502 \u251c\u2500\u2500 sample1_replicate1.macs2.unfiltered.narrowPeak \u2502 \u251c\u2500\u2500 sample1_replicate2.macs2.narrowPeak \u2502 \u251c\u2500\u2500 sample1_replicate2.macs2.narrowPeak_motif_enrichment \u2502 \u2502 \u251c\u2500\u2500 ame_results.txt \u2502 \u2502 \u251c\u2500\u2500 background.fa \u2502 \u2502 \u251c\u2500\u2500 knownResults \u2502 \u2502 \u251c\u2500\u2500 knownResults.html \u2502 \u2502 \u251c\u2500\u2500 knownResults.txt \u2502 \u2502 \u251c\u2500\u2500 motifFindingParameters.txt \u2502 \u2502 \u251c\u2500\u2500 seq.autonorm.tsv \u2502 \u2502 \u2514\u2500\u2500 target.fa \u2502 \u251c\u2500\u2500 sample1_replicate2.macs2.unfiltered.narrowPeak \u2502 \u251c\u2500\u2500 sample1.macs2.consensus.bed \u2502 \u251c\u2500\u2500 sample1.macs2.consensus.bed_motif_enrichment \u2502 \u2502 \u251c\u2500\u2500 ame_results.txt \u2502 \u2502 \u251c\u2500\u2500 background.fa \u2502 \u2502 \u251c\u2500\u2500 knownResults \u2502 \u2502 \u251c\u2500\u2500 knownResults.html \u2502 \u2502 \u251c\u2500\u2500 knownResults.txt \u2502 \u2502 \u251c\u2500\u2500 motifFindingParameters.txt \u2502 \u2502 \u251c\u2500\u2500 seq.autonorm.tsv \u2502 \u2502 \u2514\u2500\u2500 target.fa \u2502 \u251c\u2500\u2500 sample1.macs2.pooled.narrowPeak \u2502 \u251c\u2500\u2500 sample1.macs2.pooled_summits.bed \u2502 \u2514\u2500\u2500 sample1.macs2.pooled.unfiltered.narrowPeak \u251c\u2500\u2500 sample1.consensus.macs2.peakfiles \u251c\u2500\u2500 sample1.replicate.macs2.peakfiles \u251c\u2500\u2500 DiffATAC \u2502 \u251c\u2500\u2500 reads \u2502 \u2502 \u251c\u2500\u2500 all_diff_atacs.html \u2502 \u2502 \u251c\u2500\u2500 all_diff_atacs.tsv \u2502 \u2502 \u251c\u2500\u2500 degs.done \u2502 \u2502 \u251c\u2500\u2500 sample2_vs_sample1.html \u2502 \u2502 \u2514\u2500\u2500 sample2_vs_sample1.tsv \u2502 \u2514\u2500\u2500 tn5sites \u2502 \u251c\u2500\u2500 all_diff_atacs.html \u2502 \u251c\u2500\u2500 all_diff_atacs.tsv \u2502 \u251c\u2500\u2500 degs.done \u2502 \u251c\u2500\u2500 sample2_vs_sample1.html \u2502 \u2514\u2500\u2500 sample2_vs_sample1.tsv \u251c\u2500\u2500 sample2 \u2502 \u251c\u2500\u2500 sample2_replicate1.macs2.narrowPeak \u2502 \u251c\u2500\u2500 sample2_replicate1.macs2.narrowPeak_motif_enrichment \u2502 \u2502 \u251c\u2500\u2500 ame_results.txt \u2502 \u2502 \u251c\u2500\u2500 background.fa \u2502 \u2502 \u251c\u2500\u2500 knownResults \u2502 \u2502 \u251c\u2500\u2500 knownResults.html \u2502 \u2502 \u251c\u2500\u2500 knownResults.txt \u2502 \u2502 \u251c\u2500\u2500 motifFindingParameters.txt \u2502 \u2502 \u251c\u2500\u2500 seq.autonorm.tsv \u2502 \u2502 \u2514\u2500\u2500 target.fa \u2502 \u251c\u2500\u2500 sample2_replicate1.macs2.unfiltered.narrowPeak \u2502 \u251c\u2500\u2500 sample2_replicate2.macs2.narrowPeak \u2502 \u251c\u2500\u2500 sample2_replicate2.macs2.narrowPeak_motif_enrichment \u2502 \u2502 \u251c\u2500\u2500 ame_results.txt \u2502 \u2502 \u251c\u2500\u2500 background.fa \u2502 \u2502 \u251c\u2500\u2500 knownResults \u2502 \u2502 \u251c\u2500\u2500 knownResults.html \u2502 \u2502 \u251c\u2500\u2500 knownResults.txt \u2502 \u2502 \u251c\u2500\u2500 motifFindingParameters.txt \u2502 \u2502 \u251c\u2500\u2500 seq.autonorm.tsv \u2502 \u2502 \u2514\u2500\u2500 target.fa \u2502 \u251c\u2500\u2500 sample2_replicate2.macs2.unfiltered.narrowPeak \u2502 \u251c\u2500\u2500 sample2.macs2.consensus.bed \u2502 \u251c\u2500\u2500 sample2.macs2.consensus.bed_motif_enrichment \u2502 \u2502 \u251c\u2500\u2500 ame_results.txt \u2502 \u2502 \u251c\u2500\u2500 background.fa \u2502 \u2502 \u251c\u2500\u2500 knownResults \u2502 \u2502 \u251c\u2500\u2500 knownResults.html \u2502 \u2502 \u251c\u2500\u2500 knownResults.txt \u2502 \u2502 \u251c\u2500\u2500 motifFindingParameters.txt \u2502 \u2502 \u251c\u2500\u2500 seq.autonorm.tsv \u2502 \u2502 \u2514\u2500\u2500 target.fa \u2502 \u251c\u2500\u2500 sample2.macs2.pooled.narrowPeak \u2502 \u251c\u2500\u2500 sample2.macs2.pooled_summits.bed \u2502 \u2514\u2500\u2500 sample2.macs2.pooled.unfiltered.narrowPeak \u251c\u2500\u2500 sample2.consensus.macs2.peakfiles \u251c\u2500\u2500 sample2.replicate.macs2.peakfiles \u2514\u2500\u2500 fixed_width \u251c\u2500\u2500 sample1_replicate1.macs2.fixed_width.narrowPeak \u251c\u2500\u2500 sample1_replicate2.macs2.fixed_width.narrowPeak \u251c\u2500\u2500 sample1.fixed_width.consensus.narrowPeak \u251c\u2500\u2500 sample1.renormalized.fixed_width.consensus.narrowPeak \u251c\u2500\u2500 sample1.renormalized.fixed_width.consensus.narrowPeak.annotated.gz \u251c\u2500\u2500 counts \u2502 \u251c\u2500\u2500 ROI.macs2.reads_counts.tsv \u2502 \u2514\u2500\u2500 ROI.macs2.tn5sites_counts.tsv \u251c\u2500\u2500 sample2_replicate1.macs2.fixed_width.narrowPeak \u251c\u2500\u2500 sample2_replicate2.macs2.fixed_width.narrowPeak \u251c\u2500\u2500 sample2.fixed_width.consensus.narrowPeak \u251c\u2500\u2500 sample2.renormalized.fixed_width.consensus.narrowPeak \u251c\u2500\u2500 sample2.renormalized.fixed_width.consensus.narrowPeak.annotated.gz \u251c\u2500\u2500 ROI.macs2.bed \u251c\u2500\u2500 ROI.macs2.bed.annotated.gz \u251c\u2500\u2500 ROI.macs2.bed.annotated.gz.gz \u251c\u2500\u2500 ROI.macs2.bed.annotation_distribution \u251c\u2500\u2500 ROI.macs2.bed.annotation_summary \u251c\u2500\u2500 ROI.macs2.bed.genelist \u251c\u2500\u2500 ROI.macs2.gtf \u251c\u2500\u2500 ROI.macs2.narrowPeak \u251c\u2500\u2500 ROI.macs2.renormalized.narrowPeak \u2514\u2500\u2500 Rplots.pdf Some of the key output files are: File Description *.macs2.narrowPeak peak calls from MACS2 filtered by q-value for each samples each replicate *.macs2.unfiltered.narrowPeak peak calls from MACS2 (unfiltered) for each samples each replicate *.narrowPeak_motif_enrichment/ame_results.txt motif enrichment results from AME tool from MEME suite using HOCOMOCO v11 database *.narrowPeak_motif_enrichment/knownResults.txt motif enrichment results using HOMER with HOCOMOCO v11 database *.macs2.consensus.bed consensus peak call between multiple replicates of each sample. Note: consensus bed annotations are located in QC/peak_annotations DiffATAC/reads folder containing differential open chromatin results: - computated using read counts in MACS2 regions of interest (ROIs) - all_diff_atacs.html HTML report aggregated across all contrasts from contrasts.tsv - all_diff_atacs.tsv DESeq2 results in TSV format aggregated across all contrasts from contrasts.tsv - HTML and TSV file each per contrast in contrasts.tsv DiffATAC/tn5sites folder containing differential open chromatin results: - computated using Tn5 nicking site counts in MACS2 regions of interest (ROIs) - all_diff_atacs.html HTML report aggregated across all contrasts from contrasts.tsv - all_diff_atacs.tsv DESeq2 results in TSV format aggregated across all contrasts from contrasts.tsv - HTML and TSV file each per contrast in contrasts.tsv fixed_width fixed_width can be set in config.yaml to create peaks of a user defined fixed width (default 500bp). This folder contains: - individual replicate *.fixed_width.narrowPeak files - *.renormalized.fixed_width.consensus.narrowPeak per sample; Corces et. al. method is used for consensus calling; used to generate MACS2 regions of interest (ROI) peaks which are used to generate a reads or Tn5 sites counts matrix for DESeq2 - ROI related files: ROI.macs2.bed , ROI.macs2.bed.annotated.gz , ROI.macs2.annotation_summary , ROI.macs2.annotation_distribution fixed_width/counts/ROI.macs2.read_counts.tsv read counts in MACS2 ROIs using featureCounts fixed_width/counts/ROI.reads_scaled_counts.tsv ROI.macs2.read_counts.tsv scaled using spike-in scaling factors fixed_width/counts/ROI.tn5sites_counts.tsv Tn5 nicking site counts in MACS2 ROIs using featureCounts fixed_width/counts/ROI.tn5sites_scaled_counts.tsv ROI.macs2.tn5sites_counts.tsv scaled using spike-in scaling factors","title":"MACS2 output folder"},{"location":"outputs/#genrich-output-folder","text":"For a typical 2 sample analysis with 2 replicates each this folder should look like very similar to the MACS2 output structure described above.","title":"Genrich output folder"},{"location":"outputs/#logs-folder","text":"This directory contains all .err and .out log files generated by SLURM for jobs submitted via Snakemake. Each file follows a consistent naming convention: <SLURM_JOB_ID of master/head job>.<SLURM_JOB_ID of child job>.<Snakemake Rule Name>.< wildcard1_name = wildcard1_value,wildcard2_name = wildcard2_value>.<out or err> This structure is particularly useful for troubleshooting and debugging, especially when the SLURM job IDs of failed jobs are known. By examining the corresponding .err or .out files, users can efficiently identify the source of errors within specific Snakemake rules and wildcards. DISCLAIMER: This folder hierarchy is significantly different than v1.0.6 and is subject to change with subsequent versions.","title":"logs folder"},{"location":"overview/","text":"\ud83c\udf1f Overview of ASPEN \u00b6 To address these challenges, CCBR developed ASPEN ( A tac S eq P ip E li N e), an automated pipeline tailored for the comprehensive analysis of ATAC-seq data. ASPEN is designed to process paired-end Illumina sequencing data, guiding users from raw data through quality control, alignment, peak calling, and downstream analyses. By integrating a suite of established bioinformatics tools and adhering to best practices, ASPEN ensures robust, reproducible, and high-quality results. For more information on the challenges in ATAC-seq data analysis, refer to the [Challenges in ATAC-seq Data Analysis] section. Flowchart \u00b6 The flowchart below provides a visual summary of the ASPEN pipeline, illustrating the key steps involved in preprocessing, alignment, peak calling, and downstream analyses. \ud83d\udee0\ufe0f Data Preprocessing \u00b6 \u2702\ufe0f Adapter Trimming \u00b6 Utilizes CutAdapt to remove adapter sequences from raw reads, ensuring that subsequent analyses are not confounded by extraneous sequences. \ud83d\udcca Quality Assessment \u00b6 Employs FastQC for initial quality checks and MultiQC for aggregated reporting, providing comprehensive insights into data quality and highlighting potential issues such as low-quality bases or GC content biases. \ud83e\uddec Alignment and Filtering \u00b6 \ud83d\udeab Blacklist Filtering \u00b6 Reads aligning to known blacklisted regions and mitochondrial DNA are systematically removed during the preprocessing stage. Blacklisted regions, as defined by ENCODE and other genomic consortia, represent genomic loci prone to artifacts due to their repetitive nature or unusually high signal, which can confound downstream analyses. Similarly, mitochondrial reads, which often constitute a significant proportion of sequencing data, are excluded to prevent skewing results and to ensure computational resources are focused on nuclear chromatin. This filtering step enhances the accuracy and reliability of peak detection by concentrating on biologically meaningful and interpretable regions of the genome. \ud83d\udd17 Read Alignment \u00b6 Reads are aligned to the reference genome using Bowtie2, a fast and memory-efficient aligner optimized for short-read sequencing data. This step produces several key output files essential for subsequent analyses: filtered.bam : A BAM file with low-quality alignments, reads mapping to blacklisted regions removed, ensuring high-quality data for differential open chromatin analysis. qsorted.bam : A quality-sorted BAM file containing all aligned reads, serving as the primary input for Genrich peak calling. dedup.bam : A BAM file with PCR duplicates removed, used for advanced downstream analyses such as transcription factor footprinting with TOBIAS. tagAlign.gz : A compressed file containing alignment information in a simplified format, specifically prepared for MACS2 peak calling. This alignment process ensures that only high-confidence reads are retained, providing a robust foundation for accurate and reproducible ATAC-seq data analysis. \ud83d\udcc8 Peak Calling and Annotation \u00b6 \ud83d\udd0d Peak Detection \u00b6 ASPEN employs both MACS2 and Genrich for the identification of regions of open chromatin, ensuring comprehensive detection of regulatory elements. MACS2 Peak Calling \u00b6 MACS2 is employed using the default parameters recommended by the ENCODE consortium, ensuring compliance with established best practices. ASPEN produces both unfiltered and q-value filtered peak calls, striking a balance between stringency and the flexibility to examine less stringent results. Genrich Peak Calling \u00b6 Genrich is integrated into the pipeline to complement MACS2. This tool is particularly well-suited for ATAC-seq data, as it accounts for the unique characteristics of transposase-accessible regions. By leveraging Genrich, ASPEN ensures that broader regulatory elements, such as enhancers and regions of open chromatin spanning multiple nucleosomes, are accurately identified. By combining the strengths of MACS2 and Genrich, ASPEN delivers a comprehensive and reliable peak detection framework, facilitating downstream analyses and enabling researchers to uncover critical insights into chromatin accessibility and gene regulation. \ud83e\udd1d Consensus Peaks \u00b6 For datasets with multiple replicates, ASPEN employs several strategies to derive consensus peaks across replicates: consensus.bed : This file represents consensus peaks derived using the \"Consensus MAX\" strategy, as described by Yang et al. . It identifies overlapping peaks across replicates to define a shared set of regions. pooled.narrowPeak : In this approach, reads from all replicates are pooled together, and peak calling is performed on the combined dataset to generate a unified set of \"pooled\" peaks. fixed_width.consensus.narrowPeak : This method calculates consensus peaks by renormalizing p-value scores across replicates, following the approach outlined by Corces et al. . Among these methods, the fixed-width consensus peak strategy is recommended for its robustness and reproducibility. The other outputs are provided primarily for exploratory purposes. \ud83c\udff7\ufe0f Peak Annotation \u00b6 ASPEN integrates ChIPseeker to perform comprehensive annotation of identified peaks, offering valuable insights into their genomic context and potential regulatory functions. This process involves associating peaks with specific genomic features, such as promoters, enhancers, gene bodies, or intergenic regions. By providing detailed annotations, ASPEN facilitates the interpretation of chromatin accessibility data, enabling researchers to uncover the functional significance of these regions in gene regulation and other biological processes. \ud83d\uddfa\ufe0f Regions of Interest (ROI) \u00b6 Regions of Interest (ROIs) are generated through a systematic process to ensure consistency and reliability in downstream analyses: \ud83e\udde9 Replicate-Level Peaks : .narrowPeak files from individual replicates are converted into fixed-width peaks, centering on their summits and extending \u00b1250 bp to achieve a uniform width of 500 bp. \ud83e\uddec Sample-Level Consensus Peaks : Fixed-width replicate peak files are combined to generate a consensus set of peaks at the sample level, ensuring reproducibility across replicates. \ud83d\udd17 Merged ROIs : Sample-level consensus peak files are merged using the Coerses method to create a comprehensive set of ROIs. This approach ensures that ROIs represent biologically meaningful and reproducible regions, forming the foundation for robust downstream analyses. \u2705 Quality Control Metrics \u00b6 \ud83d\udccf Fragment Length Distribution \u00b6 ASPEN employs custom scripts to analyze the distribution of fragment lengths within the sequencing data. This analysis provides critical insights into nucleosome positioning and overall sample quality. Characteristic patterns, such as the presence of nucleosome-free regions and distinct mono- or di-nucleosome peaks, serve as indicators of high-quality ATAC-seq data. These patterns reflect the accessibility of chromatin and the degree of nucleosome occupancy, which are essential for interpreting chromatin structure and regulatory dynamics. \ud83d\udcda Library Complexity \u00b6 To evaluate the sufficiency of sequencing depth and detect potential biases introduced during PCR amplification, ASPEN utilizes Preseq to estimate library complexity. This metric helps determine whether the sequencing effort is adequate to capture the diversity of the library, ensuring that the data is representative of the underlying chromatin landscape. By identifying potential saturation or over-representation of certain fragments, researchers can assess the reliability of their sequencing results. \ud83e\uddec Transcription Start Site (TSS) Enrichment \u00b6 ASPEN calculates TSS enrichment scores, a widely recognized quality metric for ATAC-seq data. These scores measure the accumulation of sequencing reads around transcription start sites (TSS), which are hallmark regions of open chromatin. High TSS enrichment scores indicate well-prepared libraries with minimal technical artifacts, as they reflect the accessibility of promoter regions and the integrity of the chromatin preparation process. \ud83d\udcca Fraction of Reads in Peaks (FRiP) \u00b6 The Fraction of Reads in Peaks (FRiP) score quantifies the proportion of sequencing reads that fall within identified peaks, serving as a measure of the signal-to-noise ratio in the dataset. Higher FRiP scores indicate datasets with strong, biologically meaningful signals and minimal background noise. Additionally, ASPEN computes the fraction of reads localized to specific genomic features, such as promoters, enhancers, and DNase hypersensitive sites (DHS). These feature-specific FRiP scores provide further insights into the quality and biological relevance of the data. \ud83e\uddec Motif Enrichment Analysis \u00b6 \ud83d\udd11 HOMER and AME \u00b6 ASPEN integrates motif enrichment analysis tools, including HOMER and AME, to identify transcription factor binding motifs within accessible chromatin regions. This analysis provides valuable insights into the regulatory mechanisms governing gene expression. By uncovering enriched motifs, researchers can infer the potential transcription factors driving chromatin accessibility changes and identify key regulators of cellular processes. The combination of HOMER and AME ensures a comprehensive and robust approach to motif discovery, facilitating the interpretation of ATAC-seq data in the context of gene regulation and epigenetic control. HOCOMOCO v11 motifs, which are bundled as resources with ASPEN, are used for both motif enrichment tools. \ud83d\udcdc Comprehensive Reporting \u00b6 \ud83d\udcca MultiQC Integration \u00b6 Generates a comprehensive and interactive HTML report that consolidates all quality control metrics, analysis results, and visualizations into a single, user-friendly document. This report is designed to facilitate the interpretation of results, provide clear and actionable insights, and enable seamless sharing of findings with collaborators. By integrating diverse outputs into an organized and visually appealing format, the HTML report ensures that researchers can efficiently explore their data and communicate their discoveries effectively. \ud83d\udd0d Differential Accessibility Analyses \u00b6 ASPEN extends its core functionalities by offering advanced capabilities for differential chromatin accessibility analysis. This feature enables researchers to identify genomic regions exhibiting significant changes in chromatin accessibility under varying experimental conditions. The process encompasses several critical steps, including refining peak calls to fixed-width peaks, defining regions of interest (ROIs), quantifying Tn5 transposase insertion events, performing statistical analyses to detect differential signals, and integrating these findings with ChIP-seq annotations for comprehensive biological interpretation. \ud83d\udee0\ufe0f Refinement of Peak Calls to Fixed-Width Peaks \u00b6 Following the initial peak calling, ASPEN standardizes the identified peaks by centering them on their summits and extending them symmetrically to a uniform width of 500 base pairs (bp). This refinement ensures consistency across datasets and facilitates downstream analyses. The approach of extending peak summits by \u00b1250 bp is a widely accepted practice in ATAC-seq data analysis, as it focuses on the most accessible regions of chromatin while minimizing variability in peak sizes. This standardization enhances the comparability of results across experimental conditions and replicates. \ud83d\udccd Definition of Regions of Interest (ROIs) \u00b6 ASPEN processes the fixed-width peak calls for each replicate across all samples to generate a comprehensive union of all identified peaks, referred to as Regions of Interest (ROIs). These ROIs serve as the foundation for subsequent quantification and statistical analyses. The pipeline outputs ROI.bed and ROI.gtf files for each peak caller, which are then utilized for quantifying counts using featureCounts. This systematic approach ensures a robust and consistent framework for differential accessibility analysis, enabling reliable interpretation of the results. \ud83d\udcca Quantification of Chromatin Accessibility \u00b6 Once the ROIs are established, ASPEN generates two key count matrices to quantify chromatin accessibility: Tn5 Nicking Sites Count Matrix : This matrix quantifies the frequency of Tn5 transposase insertion events at each ROI. The filtered.bam file is used to determine Tn5 insertion sites and count them. Tn5 transposase preferentially inserts into accessible chromatin regions, and the number of insertion events serves as a direct proxy for chromatin accessibility. This metric provides a precise measure of chromatin openness across experimental conditions. Read Counts Matrix : This matrix records the number of sequencing reads mapped to each ROI. Similar to the Tn5 nicking sites matrix, the filtered.bam file is used for this quantification. While Tn5 nicking sites offer a more direct measure of chromatin accessibility, read counts are included as they are widely utilized in recent publications. Together, these matrices provide a comprehensive view of chromatin accessibility dynamics. \ud83d\udcc8 Differential Accessibility Analysis Using DESeq2 \u00b6 To identify statistically significant differences in chromatin accessibility between experimental conditions, ASPEN employs DESeq2, a widely recognized tool for differential analysis of count data. DESeq2 models the count data to detect changes in accessibility, offering robust statistical inferences even in complex experimental designs. By comparing the count matrices across conditions, DESeq2 identifies ROIs with significant differential accessibility, highlighting regulatory elements that may play critical roles in the biological context of the study. This comprehensive approach to differential accessibility analysis enables researchers to uncover key insights into chromatin dynamics, regulatory mechanisms, and gene expression changes, providing a deeper understanding of the underlying molecular processes. \ud83e\uddec Integration with Gene Annotations \u00b6 To enhance the biological interpretation of differential accessibility results, ASPEN integrates the findings with peak and gene annotations from ChIPSeeker, offering insights into the regulatory landscape of the genome. This integration allows researchers to identify genes located near differentially accessible peaks, which can be crucial for understanding the functional implications of chromatin accessibility changes. By associating these peaks with nearby genes, scientists can infer potential regulatory relationships and gain a deeper understanding of the underlying molecular mechanisms. \ud83e\uddea Optional: Spike-In Normalization \u00b6 To account for potential global shifts in chromatin accessibility\u2014particularly in perturbation studies where widespread chromatin compaction or relaxation may occur\u2014ASPEN optionally supports spike-in normalization . Spike-in normalization involves the use of exogenous DNA or cells from a different species (e.g., Drosophila melanogaster or E. coli ) that are added in equal proportions across all experimental samples prior to lysis and tagmentation. These spike-in reads serve as an internal control to correct for technical variation and global accessibility shifts that may not be captured by traditional normalization strategies. In ASPEN, if spike-in data is present: Reads are aligned to both the host and spike-in genomes using dual alignment indices. The number of spike-in reads is counted for each sample. A normalization factor is calculated based on spike-in counts and applied to the accessibility read counts from the host genome. This spike-in-derived scaling factor allows the comparison of chromatin accessibility across conditions even when global chromatin accessibility levels differ (e.g., treatment-induced repression or global decondensation). This method is particularly valuable in experiments involving: Transcription factor knockdowns/knockouts Chromatin remodeler inhibition Drug-induced chromatin modulation ASPEN performs spike-in-aware normalization transparently, and reports both raw and normalized counts in the final output matrix for differential analysis. This ensures flexibility in downstream interpretation while preserving the ability to adjust for systemic experimental artifacts. \ud83d\udcca Reporting \u00b6 ASPEN enhances differential chromatin accessibility analysis by providing an interactive HTML report generated from DESeq2 results, featuring various visualizations. Additionally, it offers a TSV (tabl-delimited) file with integrated gene annotations, compatible with Microsoft Excel, enabling efficient data manipulation and facilitating the identification of genes near regions with altered accessibility. The Excel file is aggregated accross all different contrasts queried in the project.","title":"Overview of ASPEN"},{"location":"overview/#overview-of-aspen","text":"To address these challenges, CCBR developed ASPEN ( A tac S eq P ip E li N e), an automated pipeline tailored for the comprehensive analysis of ATAC-seq data. ASPEN is designed to process paired-end Illumina sequencing data, guiding users from raw data through quality control, alignment, peak calling, and downstream analyses. By integrating a suite of established bioinformatics tools and adhering to best practices, ASPEN ensures robust, reproducible, and high-quality results. For more information on the challenges in ATAC-seq data analysis, refer to the [Challenges in ATAC-seq Data Analysis] section.","title":"\ud83c\udf1f Overview of ASPEN"},{"location":"overview/#flowchart","text":"The flowchart below provides a visual summary of the ASPEN pipeline, illustrating the key steps involved in preprocessing, alignment, peak calling, and downstream analyses.","title":"Flowchart"},{"location":"overview/#data-preprocessing","text":"","title":"\ud83d\udee0\ufe0f Data Preprocessing"},{"location":"overview/#adapter-trimming","text":"Utilizes CutAdapt to remove adapter sequences from raw reads, ensuring that subsequent analyses are not confounded by extraneous sequences.","title":"\u2702\ufe0f Adapter Trimming"},{"location":"overview/#quality-assessment","text":"Employs FastQC for initial quality checks and MultiQC for aggregated reporting, providing comprehensive insights into data quality and highlighting potential issues such as low-quality bases or GC content biases.","title":"\ud83d\udcca Quality Assessment"},{"location":"overview/#alignment-and-filtering","text":"","title":"\ud83e\uddec Alignment and Filtering"},{"location":"overview/#blacklist-filtering","text":"Reads aligning to known blacklisted regions and mitochondrial DNA are systematically removed during the preprocessing stage. Blacklisted regions, as defined by ENCODE and other genomic consortia, represent genomic loci prone to artifacts due to their repetitive nature or unusually high signal, which can confound downstream analyses. Similarly, mitochondrial reads, which often constitute a significant proportion of sequencing data, are excluded to prevent skewing results and to ensure computational resources are focused on nuclear chromatin. This filtering step enhances the accuracy and reliability of peak detection by concentrating on biologically meaningful and interpretable regions of the genome.","title":"\ud83d\udeab Blacklist Filtering"},{"location":"overview/#read-alignment","text":"Reads are aligned to the reference genome using Bowtie2, a fast and memory-efficient aligner optimized for short-read sequencing data. This step produces several key output files essential for subsequent analyses: filtered.bam : A BAM file with low-quality alignments, reads mapping to blacklisted regions removed, ensuring high-quality data for differential open chromatin analysis. qsorted.bam : A quality-sorted BAM file containing all aligned reads, serving as the primary input for Genrich peak calling. dedup.bam : A BAM file with PCR duplicates removed, used for advanced downstream analyses such as transcription factor footprinting with TOBIAS. tagAlign.gz : A compressed file containing alignment information in a simplified format, specifically prepared for MACS2 peak calling. This alignment process ensures that only high-confidence reads are retained, providing a robust foundation for accurate and reproducible ATAC-seq data analysis.","title":"\ud83d\udd17 Read Alignment"},{"location":"overview/#peak-calling-and-annotation","text":"","title":"\ud83d\udcc8 Peak Calling and Annotation"},{"location":"overview/#peak-detection","text":"ASPEN employs both MACS2 and Genrich for the identification of regions of open chromatin, ensuring comprehensive detection of regulatory elements.","title":"\ud83d\udd0d Peak Detection"},{"location":"overview/#macs2-peak-calling","text":"MACS2 is employed using the default parameters recommended by the ENCODE consortium, ensuring compliance with established best practices. ASPEN produces both unfiltered and q-value filtered peak calls, striking a balance between stringency and the flexibility to examine less stringent results.","title":"MACS2 Peak Calling"},{"location":"overview/#genrich-peak-calling","text":"Genrich is integrated into the pipeline to complement MACS2. This tool is particularly well-suited for ATAC-seq data, as it accounts for the unique characteristics of transposase-accessible regions. By leveraging Genrich, ASPEN ensures that broader regulatory elements, such as enhancers and regions of open chromatin spanning multiple nucleosomes, are accurately identified. By combining the strengths of MACS2 and Genrich, ASPEN delivers a comprehensive and reliable peak detection framework, facilitating downstream analyses and enabling researchers to uncover critical insights into chromatin accessibility and gene regulation.","title":"Genrich Peak Calling"},{"location":"overview/#consensus-peaks","text":"For datasets with multiple replicates, ASPEN employs several strategies to derive consensus peaks across replicates: consensus.bed : This file represents consensus peaks derived using the \"Consensus MAX\" strategy, as described by Yang et al. . It identifies overlapping peaks across replicates to define a shared set of regions. pooled.narrowPeak : In this approach, reads from all replicates are pooled together, and peak calling is performed on the combined dataset to generate a unified set of \"pooled\" peaks. fixed_width.consensus.narrowPeak : This method calculates consensus peaks by renormalizing p-value scores across replicates, following the approach outlined by Corces et al. . Among these methods, the fixed-width consensus peak strategy is recommended for its robustness and reproducibility. The other outputs are provided primarily for exploratory purposes.","title":"\ud83e\udd1d Consensus Peaks"},{"location":"overview/#peak-annotation","text":"ASPEN integrates ChIPseeker to perform comprehensive annotation of identified peaks, offering valuable insights into their genomic context and potential regulatory functions. This process involves associating peaks with specific genomic features, such as promoters, enhancers, gene bodies, or intergenic regions. By providing detailed annotations, ASPEN facilitates the interpretation of chromatin accessibility data, enabling researchers to uncover the functional significance of these regions in gene regulation and other biological processes.","title":"\ud83c\udff7\ufe0f Peak Annotation"},{"location":"overview/#regions-of-interest-roi","text":"Regions of Interest (ROIs) are generated through a systematic process to ensure consistency and reliability in downstream analyses: \ud83e\udde9 Replicate-Level Peaks : .narrowPeak files from individual replicates are converted into fixed-width peaks, centering on their summits and extending \u00b1250 bp to achieve a uniform width of 500 bp. \ud83e\uddec Sample-Level Consensus Peaks : Fixed-width replicate peak files are combined to generate a consensus set of peaks at the sample level, ensuring reproducibility across replicates. \ud83d\udd17 Merged ROIs : Sample-level consensus peak files are merged using the Coerses method to create a comprehensive set of ROIs. This approach ensures that ROIs represent biologically meaningful and reproducible regions, forming the foundation for robust downstream analyses.","title":"\ud83d\uddfa\ufe0f Regions of Interest (ROI)"},{"location":"overview/#quality-control-metrics","text":"","title":"\u2705 Quality Control Metrics"},{"location":"overview/#fragment-length-distribution","text":"ASPEN employs custom scripts to analyze the distribution of fragment lengths within the sequencing data. This analysis provides critical insights into nucleosome positioning and overall sample quality. Characteristic patterns, such as the presence of nucleosome-free regions and distinct mono- or di-nucleosome peaks, serve as indicators of high-quality ATAC-seq data. These patterns reflect the accessibility of chromatin and the degree of nucleosome occupancy, which are essential for interpreting chromatin structure and regulatory dynamics.","title":"\ud83d\udccf Fragment Length Distribution"},{"location":"overview/#library-complexity","text":"To evaluate the sufficiency of sequencing depth and detect potential biases introduced during PCR amplification, ASPEN utilizes Preseq to estimate library complexity. This metric helps determine whether the sequencing effort is adequate to capture the diversity of the library, ensuring that the data is representative of the underlying chromatin landscape. By identifying potential saturation or over-representation of certain fragments, researchers can assess the reliability of their sequencing results.","title":"\ud83d\udcda Library Complexity"},{"location":"overview/#transcription-start-site-tss-enrichment","text":"ASPEN calculates TSS enrichment scores, a widely recognized quality metric for ATAC-seq data. These scores measure the accumulation of sequencing reads around transcription start sites (TSS), which are hallmark regions of open chromatin. High TSS enrichment scores indicate well-prepared libraries with minimal technical artifacts, as they reflect the accessibility of promoter regions and the integrity of the chromatin preparation process.","title":"\ud83e\uddec Transcription Start Site (TSS) Enrichment"},{"location":"overview/#fraction-of-reads-in-peaks-frip","text":"The Fraction of Reads in Peaks (FRiP) score quantifies the proportion of sequencing reads that fall within identified peaks, serving as a measure of the signal-to-noise ratio in the dataset. Higher FRiP scores indicate datasets with strong, biologically meaningful signals and minimal background noise. Additionally, ASPEN computes the fraction of reads localized to specific genomic features, such as promoters, enhancers, and DNase hypersensitive sites (DHS). These feature-specific FRiP scores provide further insights into the quality and biological relevance of the data.","title":"\ud83d\udcca Fraction of Reads in Peaks (FRiP)"},{"location":"overview/#motif-enrichment-analysis","text":"","title":"\ud83e\uddec Motif Enrichment Analysis"},{"location":"overview/#homer-and-ame","text":"ASPEN integrates motif enrichment analysis tools, including HOMER and AME, to identify transcription factor binding motifs within accessible chromatin regions. This analysis provides valuable insights into the regulatory mechanisms governing gene expression. By uncovering enriched motifs, researchers can infer the potential transcription factors driving chromatin accessibility changes and identify key regulators of cellular processes. The combination of HOMER and AME ensures a comprehensive and robust approach to motif discovery, facilitating the interpretation of ATAC-seq data in the context of gene regulation and epigenetic control. HOCOMOCO v11 motifs, which are bundled as resources with ASPEN, are used for both motif enrichment tools.","title":"\ud83d\udd11 HOMER and AME"},{"location":"overview/#comprehensive-reporting","text":"","title":"\ud83d\udcdc Comprehensive Reporting"},{"location":"overview/#multiqc-integration","text":"Generates a comprehensive and interactive HTML report that consolidates all quality control metrics, analysis results, and visualizations into a single, user-friendly document. This report is designed to facilitate the interpretation of results, provide clear and actionable insights, and enable seamless sharing of findings with collaborators. By integrating diverse outputs into an organized and visually appealing format, the HTML report ensures that researchers can efficiently explore their data and communicate their discoveries effectively.","title":"\ud83d\udcca MultiQC Integration"},{"location":"overview/#differential-accessibility-analyses","text":"ASPEN extends its core functionalities by offering advanced capabilities for differential chromatin accessibility analysis. This feature enables researchers to identify genomic regions exhibiting significant changes in chromatin accessibility under varying experimental conditions. The process encompasses several critical steps, including refining peak calls to fixed-width peaks, defining regions of interest (ROIs), quantifying Tn5 transposase insertion events, performing statistical analyses to detect differential signals, and integrating these findings with ChIP-seq annotations for comprehensive biological interpretation.","title":"\ud83d\udd0d Differential Accessibility Analyses"},{"location":"overview/#refinement-of-peak-calls-to-fixed-width-peaks","text":"Following the initial peak calling, ASPEN standardizes the identified peaks by centering them on their summits and extending them symmetrically to a uniform width of 500 base pairs (bp). This refinement ensures consistency across datasets and facilitates downstream analyses. The approach of extending peak summits by \u00b1250 bp is a widely accepted practice in ATAC-seq data analysis, as it focuses on the most accessible regions of chromatin while minimizing variability in peak sizes. This standardization enhances the comparability of results across experimental conditions and replicates.","title":"\ud83d\udee0\ufe0f Refinement of Peak Calls to Fixed-Width Peaks"},{"location":"overview/#definition-of-regions-of-interest-rois","text":"ASPEN processes the fixed-width peak calls for each replicate across all samples to generate a comprehensive union of all identified peaks, referred to as Regions of Interest (ROIs). These ROIs serve as the foundation for subsequent quantification and statistical analyses. The pipeline outputs ROI.bed and ROI.gtf files for each peak caller, which are then utilized for quantifying counts using featureCounts. This systematic approach ensures a robust and consistent framework for differential accessibility analysis, enabling reliable interpretation of the results.","title":"\ud83d\udccd Definition of Regions of Interest (ROIs)"},{"location":"overview/#quantification-of-chromatin-accessibility","text":"Once the ROIs are established, ASPEN generates two key count matrices to quantify chromatin accessibility: Tn5 Nicking Sites Count Matrix : This matrix quantifies the frequency of Tn5 transposase insertion events at each ROI. The filtered.bam file is used to determine Tn5 insertion sites and count them. Tn5 transposase preferentially inserts into accessible chromatin regions, and the number of insertion events serves as a direct proxy for chromatin accessibility. This metric provides a precise measure of chromatin openness across experimental conditions. Read Counts Matrix : This matrix records the number of sequencing reads mapped to each ROI. Similar to the Tn5 nicking sites matrix, the filtered.bam file is used for this quantification. While Tn5 nicking sites offer a more direct measure of chromatin accessibility, read counts are included as they are widely utilized in recent publications. Together, these matrices provide a comprehensive view of chromatin accessibility dynamics.","title":"\ud83d\udcca Quantification of Chromatin Accessibility"},{"location":"overview/#differential-accessibility-analysis-using-deseq2","text":"To identify statistically significant differences in chromatin accessibility between experimental conditions, ASPEN employs DESeq2, a widely recognized tool for differential analysis of count data. DESeq2 models the count data to detect changes in accessibility, offering robust statistical inferences even in complex experimental designs. By comparing the count matrices across conditions, DESeq2 identifies ROIs with significant differential accessibility, highlighting regulatory elements that may play critical roles in the biological context of the study. This comprehensive approach to differential accessibility analysis enables researchers to uncover key insights into chromatin dynamics, regulatory mechanisms, and gene expression changes, providing a deeper understanding of the underlying molecular processes.","title":"\ud83d\udcc8 Differential Accessibility Analysis Using DESeq2"},{"location":"overview/#integration-with-gene-annotations","text":"To enhance the biological interpretation of differential accessibility results, ASPEN integrates the findings with peak and gene annotations from ChIPSeeker, offering insights into the regulatory landscape of the genome. This integration allows researchers to identify genes located near differentially accessible peaks, which can be crucial for understanding the functional implications of chromatin accessibility changes. By associating these peaks with nearby genes, scientists can infer potential regulatory relationships and gain a deeper understanding of the underlying molecular mechanisms.","title":"\ud83e\uddec Integration with Gene Annotations"},{"location":"overview/#optional-spike-in-normalization","text":"To account for potential global shifts in chromatin accessibility\u2014particularly in perturbation studies where widespread chromatin compaction or relaxation may occur\u2014ASPEN optionally supports spike-in normalization . Spike-in normalization involves the use of exogenous DNA or cells from a different species (e.g., Drosophila melanogaster or E. coli ) that are added in equal proportions across all experimental samples prior to lysis and tagmentation. These spike-in reads serve as an internal control to correct for technical variation and global accessibility shifts that may not be captured by traditional normalization strategies. In ASPEN, if spike-in data is present: Reads are aligned to both the host and spike-in genomes using dual alignment indices. The number of spike-in reads is counted for each sample. A normalization factor is calculated based on spike-in counts and applied to the accessibility read counts from the host genome. This spike-in-derived scaling factor allows the comparison of chromatin accessibility across conditions even when global chromatin accessibility levels differ (e.g., treatment-induced repression or global decondensation). This method is particularly valuable in experiments involving: Transcription factor knockdowns/knockouts Chromatin remodeler inhibition Drug-induced chromatin modulation ASPEN performs spike-in-aware normalization transparently, and reports both raw and normalized counts in the final output matrix for differential analysis. This ensures flexibility in downstream interpretation while preserving the ability to adjust for systemic experimental artifacts.","title":"\ud83e\uddea Optional: Spike-In Normalization"},{"location":"overview/#reporting","text":"ASPEN enhances differential chromatin accessibility analysis by providing an interactive HTML report generated from DESeq2 results, featuring various visualizations. Additionally, it offers a TSV (tabl-delimited) file with integrated gene annotations, compatible with Microsoft Excel, enabling efficient data manipulation and facilitating the identification of genes near regions with altered accessibility. The Excel file is aggregated accross all different contrasts queried in the project.","title":"\ud83d\udcca Reporting"}]}